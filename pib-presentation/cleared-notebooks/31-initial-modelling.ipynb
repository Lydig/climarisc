{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbfdd5f-3121-494c-9659-1dc09ed95b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 7.1 — USER INPUTS ===\n",
    "from pathlib import Path\n",
    "\n",
    "# Folder with your final CSVs\n",
    "DERIVED = Path(r\"..\\italy_core_data\\derived\")\n",
    "\n",
    "# >>> Pick ONE of your datasets to prepare for modeling <<<\n",
    "# Examples:\n",
    "#INPUT_CSV = DERIVED / \"maize_ITnorth_core42_1982_2016_allstressors_with_monthly.csv\"\n",
    "#INPUT_CSV = DERIVED / \"rice_ITnorth_core41_1982_2016_allstressors_with_monthly.csv\"\n",
    "#INPUT_CSV = DERIVED / \"soybean_ITnorth_core41_1982_2016_allstressors_with_monthly.csv\"\n",
    "#INPUT_CSV = DERIVED / \"wheat_spring_ITnorth_core42_1982_2016_allstressors_with_monthly.csv\"\n",
    "#INPUT_CSV = DERIVED / \"wheat_winter_ITnorth_core42_1982_2016_allstressors_with_monthly.csv\"\n",
    "#INPUT_CSV = DERIVED / \"wheat_both_ITnorth_core42_1982_2016_allstressors_with_monthly_long.csv\"\n",
    "\n",
    "# ← choose one:\n",
    "INPUT_CSV = DERIVED / \"maize_ITnorth_core42_1982_2016_allstressors_with_monthly.csv\"\n",
    "\n",
    "# Where to save the modeling table\n",
    "OUT_DIR = DERIVED / \"modeling\"\n",
    "OUT_DIR.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec11fe49-6c92-4d0e-aa49-6729f574aaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# -------- load --------\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# detect yield column dynamically (works for maize/rice/soy + wheat_* + stacked long)\n",
    "yield_cols = [c for c in df.columns if c.startswith(\"yield_\")]\n",
    "assert len(yield_cols) == 1, f\"Expected one yield_* column, found {yield_cols}\"\n",
    "YIELD_COL = yield_cols[0]\n",
    "\n",
    "# keys present\n",
    "assert {\"lat\",\"lon\",\"year\"}.issubset(df.columns)\n",
    "has_type = \"wheat_type\" in df.columns  # stacked long wheat\n",
    "\n",
    "# -------- add cell_id (stable across runs) --------\n",
    "# sort by lat,lon so IDs are reproducible\n",
    "cells = (df[[\"lat\",\"lon\"]]\n",
    "         .drop_duplicates()\n",
    "         .sort_values([\"lat\",\"lon\"])\n",
    "         .reset_index(drop=True))\n",
    "cells[\"cell_id\"] = np.arange(len(cells))\n",
    "\n",
    "df = df.merge(cells, on=[\"lat\",\"lon\"], how=\"left\")\n",
    "\n",
    "# -------- outcomes: log yield + two-way FE demeaned --------\n",
    "# sanity: yields should be > 0\n",
    "min_y = df[YIELD_COL].min()\n",
    "if not (min_y > 0):\n",
    "    raise ValueError(f\"{YIELD_COL} has non-positive values (min={min_y}). Cannot log-transform safely.\")\n",
    "\n",
    "df[\"log_yield\"] = np.log(df[YIELD_COL].values)\n",
    "\n",
    "def twoway_demean(s, ids, years):\n",
    "    mu = s.mean()\n",
    "    a = s.groupby(ids).transform(\"mean\")\n",
    "    t = s.groupby(years).transform(\"mean\")\n",
    "    return s - a - t + mu\n",
    "\n",
    "df[\"yield_fe\"]      = twoway_demean(df[YIELD_COL], df[\"cell_id\"], df[\"year\"])\n",
    "df[\"log_yield_fe\"]  = twoway_demean(df[\"log_yield\"], df[\"cell_id\"], df[\"year\"])\n",
    "\n",
    "# -------- seasonal predictors (keep raw + standardized) --------\n",
    "seasonal_vars = [\"temperature\",\"precipitation\",\"soil_water\",\"solar_radiation\",\"potential_evaporation\"]\n",
    "missing = [v for v in seasonal_vars if v not in df.columns]\n",
    "assert not missing, f\"Missing seasonal columns: {missing}\"\n",
    "\n",
    "# aridity index (mm/mm) — protect against zeros just in case\n",
    "pev = df[\"potential_evaporation\"].replace({0: np.nan})\n",
    "df[\"aridity_index\"] = df[\"precipitation\"] / pev\n",
    "\n",
    "# standardize (z-scores) — across the whole chosen dataset\n",
    "params = {\"standardization\": {}}\n",
    "for v in seasonal_vars + [\"aridity_index\"]:\n",
    "    s = df[v].astype(float)\n",
    "    mu = float(s.mean())\n",
    "    sd = float(s.std(ddof=0))\n",
    "    # avoid division by 0 if constant\n",
    "    if sd == 0 or np.isnan(sd):\n",
    "        z = pd.Series(np.zeros(len(s)), index=s.index, dtype=float)\n",
    "    else:\n",
    "        z = (s - mu) / sd\n",
    "    df[f\"{v}_z\"] = z\n",
    "    params[\"standardization\"][v] = {\"mean\": mu, \"std\": sd}\n",
    "\n",
    "# also store centered (mean-removed) versions for interpretable interactions\n",
    "for v in seasonal_vars:\n",
    "    df[f\"{v}_c\"] = df[v] - params[\"standardization\"][v][\"mean\"]\n",
    "\n",
    "# -------- light integrity checks --------\n",
    "n_rows = len(df)\n",
    "dups = df.duplicated([\"lat\",\"lon\",\"year\"] + ([\"wheat_type\"] if has_type else [])).sum()\n",
    "nans = int(df[[\"log_yield\",\"yield_fe\",\"log_yield_fe\"] + seasonal_vars].isna().sum().sum())\n",
    "\n",
    "print(f\"Rows: {n_rows}\")\n",
    "print(f\"Duplicate keys: {dups} (expect 0)\")\n",
    "print(f\"NaNs in core fields: {nans} (expect 0)\")\n",
    "print(\"Yield col:\", YIELD_COL)\n",
    "\n",
    "# -------- save --------\n",
    "stem = INPUT_CSV.stem.replace(\"_allstressors_with_monthly\",\"\").replace(\"_allstressors\",\"\")\n",
    "out_csv  = OUT_DIR / f\"{stem}_modeling.csv\"\n",
    "out_json = OUT_DIR / f\"{stem}_modeling_params.json\"\n",
    "\n",
    "df.to_csv(out_csv, index=False)\n",
    "with open(out_json, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"input_file\": str(INPUT_CSV),\n",
    "        \"yield_col\": YIELD_COL,\n",
    "        \"n_rows\": n_rows,\n",
    "        \"n_cells\": int(cells.shape[0]),\n",
    "        \"years\": {\"min\": int(df[\"year\"].min()), \"max\": int(df[\"year\"].max())},\n",
    "        \"has_wheat_type\": bool(has_type),\n",
    "        **params\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" •\", out_csv)\n",
    "print(\" •\", out_json)\n",
    "\n",
    "# preview a few columns you’ll model with\n",
    "show_cols = [\"lat\",\"lon\",\"cell_id\",\"year\"] + ([\"wheat_type\"] if has_type else []) + \\\n",
    "            [YIELD_COL,\"log_yield\",\"yield_fe\",\"log_yield_fe\"] + \\\n",
    "            [\"temperature_z\",\"precipitation_z\",\"soil_water_z\",\"solar_radiation_z\",\"potential_evaporation_z\",\"aridity_index_z\"]\n",
    "print(\"\\nPreview:\")\n",
    "print(df[show_cols].head(8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738b71f4-22d1-45fe-9108-bee9f09a3ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 7.2 — Baseline seasonal multiple regression (clustered by cell) ===\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "DERIVED = Path(r\"..\\italy_core_data\\derived\")\n",
    "MODEL_DIR = DERIVED / \"modeling\"\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Pick the modeling CSV you just created in 7.1 (maize here, but any dataset works)\n",
    "model_csv = MODEL_DIR / \"maize_ITnorth_core42_1982_2016_modeling.csv\"\n",
    "df = pd.read_csv(model_csv)\n",
    "\n",
    "# Columns\n",
    "y = \"log_yield_fe\"   # two-way demeaned log yield\n",
    "X_base = [\"temperature_z\",\"precipitation_z\",\"soil_water_z\",\"solar_radiation_z\",\"potential_evaporation_z\"]\n",
    "\n",
    "# Add a simple interaction (centered vars so main effects are interpretable at avg climate)\n",
    "df[\"temp_x_precip\"] = (df[\"temperature_c\"] * df[\"precipitation_c\"]).astype(float)\n",
    "X = X_base + [\"temp_x_precip\"]\n",
    "\n",
    "# Build design matrix\n",
    "Xmat = sm.add_constant(df[X].astype(float))\n",
    "yvec = df[y].astype(float)\n",
    "\n",
    "# Fit OLS with cluster-robust SE by cell\n",
    "model = sm.OLS(yvec, Xmat, missing=\"drop\")\n",
    "res = model.fit(cov_type=\"cluster\", cov_kwds={\"groups\": df[\"cell_id\"]})\n",
    "\n",
    "# Print compact summary\n",
    "print(res.summary())\n",
    "\n",
    "# Tidy coefficient table with clustered SE and 95% CI\n",
    "coefs = (pd.DataFrame({\n",
    "    \"term\": [\"const\"] + X,\n",
    "    \"estimate\": res.params.values,\n",
    "    \"std_error\": res.bse.values,\n",
    "    \"t_value\": res.tvalues.values,\n",
    "    \"p_value\": res.pvalues.values,\n",
    "})\n",
    ".assign(ci_lo=lambda d: d[\"estimate\"] - 1.96*d[\"std_error\"])\n",
    ".assign(ci_hi=lambda d: d[\"estimate\"] + 1.96*d[\"std_error\"])\n",
    ")\n",
    "\n",
    "out_coef = MODEL_DIR / \"maize_baseline_coefficients.csv\"\n",
    "coefs.to_csv(out_coef, index=False)\n",
    "\n",
    "# Simple fit diagnostics\n",
    "print(\"\\nN =\", int(res.nobs), \"| R-squared (within-FE spec proxy):\", f\"{res.rsquared:.3f}\")\n",
    "print(\"Saved coef table →\", out_coef)\n",
    "\n",
    "# Optional quick sanity: group means of yield_fe should be ~0\n",
    "cell_means = df.groupby(\"cell_id\")[\"yield_fe\"].mean().abs().max()\n",
    "year_means = df.groupby(\"year\")[\"yield_fe\"].mean().abs().max()\n",
    "print(f\"Max |mean(yield_fe)| by cell: {cell_means:.3e} ; by year: {year_means:.3e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde0a76f-77d6-4d8c-ba5c-4198dada475d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
