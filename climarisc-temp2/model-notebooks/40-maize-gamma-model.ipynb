{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8de28b9",
   "metadata": {},
   "source": [
    "# EDA for Maize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54350fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import scipy.stats as stats\n",
    "from patsy import dmatrices\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c86e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis - Full Correlation Matrix\n",
    "\n",
    "print(\"--- EDA: Correlation Analysis of All Monthly Stressors ---\")\n",
    "\n",
    "# --- 1. Load the Data ---\n",
    "# As confirmed, this file is already specific to maize and its growing season.\n",
    "file_path = '../data-cherry-pick/maize_ITnorth_core42_1982_2016_allstressors_with_monthly.csv'\n",
    "\n",
    "try:\n",
    "    df_maize = pd.read_csv(file_path)\n",
    "    print(f\"Successfully loaded dataset from: {file_path}\")\n",
    "\n",
    "    # --- 2. Select Only the Monthly Stressor Variables ---\n",
    "    # We will select all columns that have a month name in them, which is a robust\n",
    "    # way to grab all the monthly predictors we want to investigate.\n",
    "    monthly_stressors = [col for col in df_maize.columns if '_' in col and 'yield' not in col]\n",
    "    df_corr = df_maize[monthly_stressors]\n",
    "    \n",
    "    print(f\"\\nSelected {len(df_corr.columns)} monthly stressor variables for correlation analysis.\")\n",
    "\n",
    "    # --- 3. Calculate and Print the Correlation Matrix ---\n",
    "    correlation_matrix = df_corr.corr()\n",
    "    \n",
    "    # Optional: If you want to see the full numerical matrix, uncomment the next line\n",
    "    # print(\"\\n--- Full Pairwise Correlation Matrix ---\")\n",
    "    # print(correlation_matrix)\n",
    "\n",
    "    # --- 4. Visualize the Matrix with a Heatmap ---\n",
    "    # A heatmap is the best way to see the broad patterns of collinearity.\n",
    "    print(\"\\nGenerating correlation heatmap...\")\n",
    "    \n",
    "    plt.figure(figsize=(18, 15))\n",
    "    heatmap = sns.heatmap(\n",
    "        correlation_matrix,\n",
    "        cmap='coolwarm',  # Use a diverging colormap (red=positive, blue=negative)\n",
    "        center=0,         # Center the colormap at zero\n",
    "        vmin=-1,          # Set the color scale limits to the theoretical min/max\n",
    "        vmax=1,\n",
    "        linewidths=.5,\n",
    "        annot=False       # Annotations are turned off as the matrix is too large to be readable\n",
    "    )\n",
    "    \n",
    "    plt.title('Pairwise Correlation Matrix of All Monthly Stressors for Rice', fontsize=20)\n",
    "    plt.show()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at the specified path: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0f1ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Extended EDA for Maize Yield Analysis ---\")\n",
    "\n",
    "# --- 1. Load the Data ---\n",
    "file_path = '../data-cherry-pick/maize_ITnorth_core42_1982_2016_allstressors_with_monthly.csv'\n",
    "\n",
    "try:\n",
    "    df_maize = pd.read_csv(file_path)\n",
    "    print(f\"Successfully loaded dataset from: {file_path}\\n\")\n",
    "\n",
    "    # --- Task 1: Examine the Distribution of the Dependent Variable (yield_maize) ---\n",
    "    print(\"--- Task 1: Analyzing the distribution of the dependent variable 'yield_maize' ---\")\n",
    "    \n",
    "    # Create a figure with two subplots side-by-side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    fig.suptitle('Distribution Analysis for yield_maize', fontsize=16)\n",
    "\n",
    "    # a) Histogram with a Kernel Density Estimate (KDE)\n",
    "    # This helps us visually assess the shape, center, and spread of the yield data.\n",
    "    # We are checking for positive skewness, which is characteristic of data modeled by a Gamma distribution.\n",
    "    sns.histplot(df_maize['yield_maize'], kde=True, ax=axes[0])\n",
    "    axes[0].set_title('Histogram of Maize Yield')\n",
    "    axes[0].set_xlabel('Yield (tonnes per hectare)')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "\n",
    "    # b) Q-Q (Quantile-Quantile) Plot against a theoretical normal distribution\n",
    "    # This plot helps us assess if the data's distribution follows a specific theoretical distribution.\n",
    "    # Deviations from the red line suggest skewness or heavy tails.\n",
    "    # While our target is a Gamma GLM, a Q-Q plot vs. Normal is a standard first step to detect non-normality.\n",
    "    stats.probplot(df_maize['yield_maize'], dist=\"norm\", plot=axes[1])\n",
    "    axes[1].set_title('Q-Q Plot of Maize Yield vs. Normal Distribution')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "    print(\"Distribution plots generated. Check for positive skew, which supports our choice of a Gamma GLM.\\n\")\n",
    "\n",
    "\n",
    "    # --- Task 2: Bivariate Scatter Plots of Yield vs. Key Stressors ---\n",
    "    print(\"--- Task 2: Visualizing relationships between yield and key climate stressors ---\")\n",
    "    \n",
    "    # Select a few key stressors based on agronomic theory for Maize\n",
    "    key_stressors = ['temperature_Jul', 'precipitation_Jun', 'soil_water_Aug']\n",
    "    \n",
    "    # Create a figure to hold the scatter plots\n",
    "    fig, axes = plt.subplots(1, len(key_stressors), figsize=(21, 6))\n",
    "    fig.suptitle('Bivariate Relationships: Maize Yield vs. Key Stressors', fontsize=16)\n",
    "\n",
    "    for i, stressor in enumerate(key_stressors):\n",
    "        # We use a regression plot with a LOWESS (Locally Weighted Scatterplot Smoothing) curve.\n",
    "        # This is a non-parametric way to see the underlying trend without assuming a linear relationship.\n",
    "        # It's excellent for spotting potential non-linearities (like an inverted 'U' shape).\n",
    "        sns.regplot(\n",
    "            x=stressor,\n",
    "            y='yield_maize',\n",
    "            data=df_maize,\n",
    "            ax=axes[i],\n",
    "            lowess=True, # Use LOWESS smoother to detect non-linear patterns\n",
    "            scatter_kws={'alpha': 0.1, 'color': 'gray'}, # De-emphasize individual points\n",
    "            line_kws={'color': 'blue'} # Emphasize the trend line\n",
    "        )\n",
    "        axes[i].set_title(f'Yield vs. {stressor}')\n",
    "        axes[i].set_xlabel(f'{stressor}')\n",
    "        axes[i].set_ylabel('Yield (tonnes per hectare)')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "    print(\"Scatter plots generated. Look for non-linear patterns that might inform our final model.\\n\")\n",
    "\n",
    "\n",
    "    # --- Task 3: Plot Key Variables Over Time ---\n",
    "    print(\"--- Task 3: Examining long-term trends in yield and a key climate variable ---\")\n",
    "    \n",
    "    # Calculate the mean of yield and a key stressor for each year\n",
    "    yearly_data = df_maize.groupby('year')[['yield_maize', 'temperature_Jul']].mean().reset_index()\n",
    "\n",
    "    # Create a plot with a primary and secondary y-axis to show both trends together.\n",
    "    # This confirms the necessity of including 'year' as a control variable to capture trends\n",
    "    # likely related to technology, while also checking for climate trends.\n",
    "    fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "    # Plotting average yield on the primary (left) y-axis\n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Year')\n",
    "    ax1.set_ylabel('Average Yield (tonnes per hectare)', color=color)\n",
    "    ax1.plot(yearly_data['year'], yearly_data['yield_maize'], color=color, marker='o', label='Average Yield')\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    # Create a second y-axis that shares the same x-axis\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    # Plotting average temperature on the secondary (right) y-axis\n",
    "    color = 'tab:red'\n",
    "    ax2.set_ylabel('Average July Temperature (°C)', color=color)\n",
    "    ax2.plot(yearly_data['year'], yearly_data['temperature_Jul'], color=color, linestyle='--', marker='x', label='Avg. July Temp')\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    plt.title('Long-Term Trend of Maize Yield and July Temperature (1982-2016)', fontsize=16)\n",
    "    fig.tight_layout()\n",
    "    # Adding a single legend for both lines\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "    \n",
    "    plt.show()\n",
    "    print(\"Time-series plot generated. Note the clear upward trend in yield, confirming the need for a 'year' control variable.\\n\")\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at the specified path: {file_path}\")\n",
    "except KeyError as e:\n",
    "    print(f\"ERROR: A required column was not found in the dataset: {e}. Please check the CSV file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2008f08",
   "metadata": {},
   "source": [
    "# Regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fb9a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load the Data ---\n",
    "file_path = '../data-cherry-pick/maize_ITnorth_core42_1982_2016_allstressors_with_monthly.csv'\n",
    "\n",
    "try:\n",
    "    df_maize = pd.read_csv(file_path)\n",
    "    print(f\"Successfully loaded dataset from: {file_path}\")\n",
    "\n",
    "    # --- 2. Define the Full Model Formula ---\n",
    "    # Programmatically get all monthly stressor column names\n",
    "    monthly_stressors = [col for col in df_maize.columns if '_' in col and 'yield' not in col]\n",
    "    \n",
    "    # Join them with '+' to create the predictor part of the formula\n",
    "    stressor_formula_part = ' + '.join(monthly_stressors)\n",
    "    \n",
    "    # Construct the complete R-style formula string.\n",
    "    # We include our controls (year, spatial splines) and all potential predictors.\n",
    "    # Note: patsy's bs() function creates the basis spline columns.\n",
    "    formula = f\"yield_maize ~ year + bs(lat, df=4) + bs(lon, df=4) + {stressor_formula_part}\"\n",
    "    \n",
    "    print(\"\\nGenerated model formula for patsy:\")\n",
    "    print(formula) # Uncomment to see the full, very long formula string\n",
    "\n",
    "    # --- 3. Create the Design Matrix (X) and Response Vector (y) ---\n",
    "    # patsy processes the formula and the dataframe to create the matrices needed for modeling.\n",
    "    # 'y' will be our dependent variable, 'X' will be the full set of predictors.\n",
    "    # The intercept is automatically included in 'X' by patsy.\n",
    "    print(\"\\nCreating design matrix (X) and response vector (y) using patsy...\")\n",
    "    y, X = dmatrices(formula, data=df_maize, return_type='dataframe')\n",
    "    \n",
    "    print(f\"Successfully created response vector y with shape: {y.shape}\")\n",
    "    print(f\"Successfully created design matrix X with shape: {X.shape}\")\n",
    "    print(f\"The {X.shape[1]} columns in X include the intercept, year, 8 spline bases (4 for lat, 4 for lon), and {len(monthly_stressors)} climate stressors.\")\n",
    "\n",
    "    # --- 4. Standardize the Predictor Matrix (X) ---\n",
    "    # We scale ALL predictors to have a mean of 0 and a standard deviation of 1.\n",
    "    # This ensures the regularization penalty is applied fairly to all variables.\n",
    "    # We do NOT scale the response variable y.\n",
    "    print(\"\\nStandardizing the design matrix X...\")\n",
    "    \n",
    "    # We remove the Intercept column before scaling, as it should not be regularized or scaled.\n",
    "    # We will add it back later if needed, but scikit-learn's models handle it by default.\n",
    "    X_no_intercept = X.drop('Intercept', axis=1)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled_values = scaler.fit_transform(X_no_intercept)\n",
    "    \n",
    "    # Convert the scaled array back to a pandas DataFrame with the original column names\n",
    "    X_scaled = pd.DataFrame(X_scaled_values, columns=X_no_intercept.columns, index=X.index)\n",
    "    \n",
    "    print(\"Standardization complete.\")\n",
    "    \n",
    "    # Verification: Check the mean and standard deviation of a few scaled columns\n",
    "    print(\"\\n--- Verification of Standardization ---\")\n",
    "    verification_cols = ['year', 'bs(lat, df=4)[0]', 'temperature_Jul']\n",
    "    for col in verification_cols:\n",
    "        mean_val = X_scaled[col].mean()\n",
    "        std_val = X_scaled[col].std()\n",
    "        print(f\"Column '{col}': Mean = {mean_val:.4f}, Std Dev = {std_val:.4f}\")\n",
    "    print(\"------------------------------------\")\n",
    "    \n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at the specified path: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e4fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume 'y' and 'X_scaled' are already in memory from the previous step.\n",
    "# If not, you would need to re-run the data preparation script.\n",
    "\n",
    "try:\n",
    "    # --- 1. Define the GLM Model ---\n",
    "    # We specify our model family (Gamma) and the link function (log) as per our project plan.\n",
    "    # We pass the prepared y and the fully scaled X matrix.\n",
    "    # Note: statsmodels requires the intercept to be in the X matrix, which patsy provided.\n",
    "    \n",
    "    # We need to add the intercept back to the scaled data for statsmodels GLM\n",
    "    X_scaled_with_intercept = X.copy() # Start with the original X to preserve intercept and structure\n",
    "    X_scaled_with_intercept[X_no_intercept.columns] = X_scaled # Replace non-intercept columns with scaled versions\n",
    "\n",
    "    gl_gamma = sm.GLM(y, X_scaled_with_intercept, family=sm.families.Gamma(link=sm.families.links.log()))\n",
    "    print(\"Successfully initialized Gamma GLM with a log link.\")\n",
    "\n",
    "    # --- 2. Set up the Regularization Path ---\n",
    "    # We need to test a series of alpha values (penalty strengths).\n",
    "    # A logarithmic scale is best for this, from a weak penalty to a strong one.\n",
    "    n_alphas = 100\n",
    "    alphas = np.logspace(-3, 0.5, n_alphas) # From 0.001 to ~3.16\n",
    "\n",
    "    # The L1_wt parameter controls the Elastic Net mix (0=Ridge, 1=Lasso). \n",
    "    # 0.5 is a balanced choice.\n",
    "    elastic_net_l1_wt = 0.5 \n",
    "    \n",
    "    print(f\"Will fit the model for {n_alphas} alpha values with L1_wt (l1_ratio) = {elastic_net_l1_wt}\")\n",
    "\n",
    "    # --- 3. Fit the Model for Each Alpha and Store Coefficients ---\n",
    "    # We will loop through our alphas and save the coefficients from each model fit.\n",
    "    coefficients = []\n",
    "    \n",
    "    for alpha_val in alphas:\n",
    "        # The fit_regularized method performs the Elastic Net estimation.\n",
    "        # We set refit=False because we want to see the shrunken coefficients for this analysis.\n",
    "        results = gl_gamma.fit_regularized(\n",
    "            method='elastic_net', \n",
    "            alpha=alpha_val, \n",
    "            L1_wt=elastic_net_l1_wt,\n",
    "            refit=False \n",
    "        )\n",
    "        coefficients.append(results.params)\n",
    "    \n",
    "    # Convert the list of coefficient series into a DataFrame for easy plotting\n",
    "    coef_df = pd.DataFrame(coefficients, index=alphas)\n",
    "    coef_df.index.name = \"alpha\"\n",
    "    \n",
    "    # Exclude the Intercept for plotting, as it's not regularized and has a different scale.\n",
    "    coef_df_no_intercept = coef_df.drop('Intercept', axis=1)\n",
    "    \n",
    "    print(\"\\nCompleted fitting models along the regularization path.\")\n",
    "\n",
    "    # --- 4. Visualize the Regularization Path ---\n",
    "    print(\"Generating the regularization path plot...\")\n",
    "    \n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(16, 10))\n",
    "\n",
    "    ax.plot(coef_df_no_intercept)\n",
    "    ax.set_xscale('log') # The alpha path is best viewed on a log scale\n",
    "    \n",
    "    # Add a vertical line at zero\n",
    "    ax.axhline(0, color='black', linewidth=0.5, linestyle='--')\n",
    "    \n",
    "    ax.set_title('Regularization Path for Rice Model Coefficients (Elastic Net)', fontsize=18)\n",
    "    ax.set_xlabel('Alpha (Penalty Strength)', fontsize=14)\n",
    "    ax.set_ylabel('Standardized Coefficient Value', fontsize=14)\n",
    "    \n",
    "    # To avoid a cluttered legend, we don't add one here. The goal is to see the general pattern.\n",
    "    # Alternatively, for fewer variables, a legend could be useful:\n",
    "    # ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "except NameError:\n",
    "    print(\"ERROR: Make sure that 'y' and 'X_scaled' DataFrames from the previous step are available in memory.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561f71f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Corrected code to identify the most robust variables ---\n",
    "# We will inspect the coefficients at a moderately high alpha value\n",
    "# This tells us which variables \"survived\" the penalty the longest.\n",
    "alpha_to_inspect = 0.03 \n",
    "\n",
    "try:\n",
    "    # Find the alpha in our index that is closest to our target\n",
    "    # CORRECTED LINE: The operation works directly on the index without .flat\n",
    "    closest_alpha = coef_df.index[np.abs(coef_df.index - alpha_to_inspect).argmin()]\n",
    "\n",
    "    print(f\"--- Coefficients at alpha ≈ {closest_alpha:.4f} ---\")\n",
    "\n",
    "    # Get the coefficients at this alpha and sort them by absolute value\n",
    "    robust_coeffs = coef_df.loc[closest_alpha].copy()\n",
    "    robust_coeffs_sorted = robust_coeffs.abs().sort_values(ascending=False)\n",
    "\n",
    "    print(\"\\nVariables sorted by the absolute magnitude of their shrunken coefficient:\")\n",
    "    # We display more variables to get a fuller picture\n",
    "    print(robust_coeffs_sorted.head(15))\n",
    "\n",
    "    # Let's also see their actual values (positive or negative) for the top variables\n",
    "    print(\"\\n--- Actual coefficient values for the most robust variables ---\")\n",
    "    print(coef_df.loc[closest_alpha, robust_coeffs_sorted.index].head(10))\n",
    "\n",
    "except NameError:\n",
    "     print(\"ERROR: Make sure that 'coef_df' DataFrame from the previous step is available in memory.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed63896",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Fitting the Base Champion Model ---\")\n",
    "\n",
    "# --- 1. Load the Data ---\n",
    "# We use the original dataframe for this step.\n",
    "file_path = '../data-cherry-pick/maize_ITnorth_core42_1982_2016_allstressors_with_monthly.csv'\n",
    "\n",
    "try:\n",
    "    df_maize = pd.read_csv(file_path)\n",
    "    print(f\"Successfully loaded dataset from: {file_path}\\n\")\n",
    "\n",
    "    # --- 2. Define and Fit the Champion Model ---\n",
    "    # This formula contains only the variables that proved robust in the regularization step.\n",
    "    # We use statsmodels.formula.api which simplifies fitting models from a formula string.\n",
    "    champion_formula = \"yield_maize ~ year + bs(lat, df=4) + bs(lon, df=4) + potential_evaporation_May + soil_water + temperature_Jul + precipitation_Sep + precipitation_Jun\"\n",
    "\n",
    "    # Initialize the GLM model using the formula and the dataframe.\n",
    "    # Specify the Gamma family with a log link as planned.\n",
    "    base_model = smf.glm(\n",
    "        formula=champion_formula,\n",
    "        data=df_maize,\n",
    "        family=sm.families.Gamma(link=sm.families.links.log())\n",
    "    )\n",
    "\n",
    "    # Fit the model. This is the standard, un-penalized fit.\n",
    "    base_model_results = base_model.fit()\n",
    "\n",
    "    # --- 3. Print the Full Summary for Interpretation ---\n",
    "    # This summary is now statistically valid and is the basis for our interpretation.\n",
    "    print(\"--- Summary of the Base Champion Model ---\")\n",
    "    print(base_model_results.summary())\n",
    "\n",
    "    # --- 4. Print AIC for Future Comparison ---\n",
    "    # The AIC is a key metric for comparing different model formulations. Lower is better.\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"AIC for Base Champion Model: {base_model_results.aic:.2f}\")\n",
    "    print(\"This will be our benchmark for comparison.\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at the specified path: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746c7391",
   "metadata": {},
   "source": [
    "## analysis\n",
    "\n",
    "This is a really good starting point. High explanitory power and almost all variables are significant. We will test a simplified version of this model which excludes the non-significant variable next, and see if the model improves (The Principle of Parsimony). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded373d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Fitting a Simplified Base Champion Model ---\")\n",
    "\n",
    "# --- 1. Load the Data ---\n",
    "file_path = '../data-cherry-pick/maize_ITnorth_core42_1982_2016_allstressors_with_monthly.csv'\n",
    "\n",
    "try:\n",
    "    df_maize = pd.read_csv(file_path)\n",
    "    print(f\"Successfully loaded dataset from: {file_path}\\n\")\n",
    "\n",
    "    # --- 2. Define and Fit the Simplified Champion Model ---\n",
    "    # We have removed 'precipitation_Jun' based on its high p-value (0.587) in the previous model.\n",
    "    # This is a test of the Principle of Parsimony.\n",
    "    simplified_formula = \"yield_maize ~ year + bs(lat, df=4) + bs(lon, df=4) + potential_evaporation_May + soil_water + temperature_Jul + precipitation_Sep\"\n",
    "\n",
    "    # Initialize the GLM model using the new, simplified formula.\n",
    "    base_model_simplified = smf.glm(\n",
    "        formula=simplified_formula,\n",
    "        data=df_maize,\n",
    "        family=sm.families.Gamma(link=sm.families.links.log())\n",
    "    )\n",
    "\n",
    "    # Fit the model.\n",
    "    base_model_simplified_results = base_model_simplified.fit()\n",
    "\n",
    "    # --- 3. Print the Full Summary for Interpretation ---\n",
    "    print(\"--- Summary of the Simplified Base Champion Model ---\")\n",
    "    print(base_model_simplified_results.summary())\n",
    "\n",
    "    # --- 4. Print AIC for Comparison ---\n",
    "    # We will compare this AIC to the previous model's AIC (5327.32).\n",
    "    # A lower or similar AIC will justify removing the variable.\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"AIC for Simplified Base Model: {base_model_simplified_results.aic:.2f}\")\n",
    "    print(\"Compare this to the previous Base Champion Model's AIC (5327.32).\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at the specified path: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d607b53",
   "metadata": {},
   "source": [
    "## analysis\n",
    "\n",
    "AIC improved, all stressors are significant, and we explain a high amount oif variation in yield. This is our new champion.\n",
    "\n",
    "Next, we test for non linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a43a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Testing for Non-Linearity (Quadratic Term for temp_Jul) ---\")\n",
    "\n",
    "# --- 1. Load the Data ---\n",
    "file_path = '../data-cherry-pick/maize_ITnorth_core42_1982_2016_allstressors_with_monthly.csv'\n",
    "\n",
    "try:\n",
    "    df_maize = pd.read_csv(file_path)\n",
    "    print(f\"Successfully loaded dataset from: {file_path}\\n\")\n",
    "\n",
    "    # --- 2. Define and Fit the Model with the Quadratic Term ---\n",
    "    # We build on our simplified champion model by adding a squared term for temperature_Jul.\n",
    "    # This directly tests the inverted U-shape hypothesis from our EDA.\n",
    "    # The I() function tells patsy to treat the operation inside as a mathematical formula.\n",
    "    quadratic_formula = \"yield_maize ~ year + bs(lat, df=4) + bs(lon, df=4) + potential_evaporation_May + soil_water + temperature_Jul + I(temperature_Jul**2) + precipitation_Sep\"\n",
    "\n",
    "    # Initialize the GLM model using the new quadratic formula.\n",
    "    quadratic_model = smf.glm(\n",
    "        formula=quadratic_formula,\n",
    "        data=df_maize,\n",
    "        family=sm.families.Gamma(link=sm.families.links.log())\n",
    "    )\n",
    "\n",
    "    # Fit the model.\n",
    "    quadratic_model_results = quadratic_model.fit()\n",
    "\n",
    "    # --- 3. Print the Full Summary for Interpretation ---\n",
    "    print(\"--- Summary of the Model with Quadratic Term ---\")\n",
    "    print(quadratic_model_results.summary())\n",
    "\n",
    "    # --- 4. Print AIC for Comparison ---\n",
    "    # We will compare this AIC to our new champion's AIC (5325.61).\n",
    "    # A lower AIC will indicate that capturing the non-linear effect is an improvement.\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"AIC for Quadratic Model: {quadratic_model_results.aic:.2f}\")\n",
    "    print(\"Compare this to the Simplified Base Model's AIC (5325.61).\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at the specified path: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6c6ad4",
   "metadata": {},
   "source": [
    "## interpretation\n",
    "\n",
    "Our new non linear model has a way better AIC, and eplains a tiny bit more of the variation in maize yield. \n",
    "\n",
    "Adding the non linear version of July temperature was highly successful and significant, but it rendered the linear july temp variable non signfificant. This is most likly due to the qudratic term capturing the inverted u shape of the data so well, that the simple linear term becomes redundant. But we keep both due to the principle of hierarchy. \n",
    "\n",
    "Next we will test of Sep precipitation should also be non linear. For simplicity reasons, since this did not yield an improved model, I will not incldue the code. But the new term was not signfiicnat, so we keep our champion model as:\n",
    "\n",
    "\"yield_maize ~ year + bs(lat, df=4) + bs(lon, df=4) + potential_evaporation_May + soil_water + temperature_Jul + I(temperature_Jul**2) + precipitation_Sep\"\n",
    "\n",
    "\n",
    "The next steps are to test for interractions. We want to start with heat and water stress:\n",
    "The Hypothesis: The negative impact of high temperature_Jul is made much worse when there is also a lack of water. Conversely, having ample water can help the plant cool itself (through transpiration) and partially mitigate the effects of heat stress. This was also not an improvemtn, so we reject the model. Again, for efficiiency, im not including the code unless its an improvment. \n",
    "\n",
    "lASTLY WE WANT TO TEST IF USING INDIVIDUAL MONTH AVERAGES FOR SOIL WATER IS AN IMPROVEMNT over using the full growing season average. Again, non showed an improvment over the current champion model, so we do not include the code for it. This ends our model development and now we can move into interpetations and visualisations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91fcbfb",
   "metadata": {},
   "source": [
    "## visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31437a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Generating Yield Response Curves for Maize ---\")\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "file_path = '../data-cherry-pick/maize_ITnorth_core42_1982_2016_allstressors_with_monthly.csv'\n",
    "df_maize = pd.read_csv(file_path)\n",
    "df_maize = df_maize[df_maize['yield_maize'] > 0].copy()\n",
    "print(\"Data prepared successfully.\")\n",
    "\n",
    "# --- 2. Fit Our Final Champion Model ---\n",
    "# We can use the simple formula here; statsmodels/patsy will handle the splines.\n",
    "final_champion_formula = \"yield_maize ~ year + bs(lat, df=4) + bs(lon, df=4) + potential_evaporation_May + soil_water + temperature_Jul + I(temperature_Jul**2) + precipitation_Sep\"\n",
    "\n",
    "print(\"Fitting Final Champion model...\")\n",
    "final_model = smf.glm(\n",
    "    formula=final_champion_formula,\n",
    "    data=df_maize,\n",
    "    family=sm.families.Gamma(link=sm.families.links.log())\n",
    ").fit()\n",
    "print(f\"Model fitted successfully. AIC: {final_model.aic:.2f}\")\n",
    "\n",
    "\n",
    "# --- 3. Prepare a Base Prediction DataFrame with Mean/Median Values (THE FIX) ---\n",
    "# This is the stable base for our plots. We use the median for robustness.\n",
    "# CRUCIALLY, we MUST include lat and lon themselves for the spline prediction to work.\n",
    "mean_values = {\n",
    "    'year': df_maize['year'].median(),\n",
    "    'potential_evaporation_May': df_maize['potential_evaporation_May'].median(),\n",
    "    'soil_water': df_maize['soil_water'].median(),\n",
    "    'temperature_Jul': df_maize['temperature_Jul'].median(),\n",
    "    'precipitation_Sep': df_maize['precipitation_Sep'].median(),\n",
    "    'lat': df_maize['lat'].median(), # Added lat\n",
    "    'lon': df_maize['lon'].median()  # Added lon\n",
    "}\n",
    "\n",
    "# --- VISUALIZATION 1: The Temperature Response Curve ---\n",
    "print(\"\\nGenerating plot 1: Non-Linear Yield Response to July Temperature...\")\n",
    "\n",
    "temp_jul_range = np.linspace(df_maize['temperature_Jul'].min(), df_maize['temperature_Jul'].max(), 100)\n",
    "\n",
    "pred_df_temp = pd.DataFrame(mean_values, index=range(100))\n",
    "pred_df_temp['temperature_Jul'] = temp_jul_range\n",
    "\n",
    "preds_temp = final_model.get_prediction(pred_df_temp)\n",
    "pred_summary_temp = preds_temp.summary_frame(alpha=0.05)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(pred_df_temp['temperature_Jul'], pred_summary_temp['mean'], color='red', linewidth=3, label='Predicted Yield')\n",
    "plt.fill_between(pred_df_temp['temperature_Jul'], pred_summary_temp['mean_ci_lower'], pred_summary_temp['mean_ci_upper'], color='red', alpha=0.2, label='95% Confidence Interval')\n",
    "plt.scatter(df_maize['temperature_Jul'], df_maize['yield_maize'], alpha=0.05, color='gray', label='Raw Data')\n",
    "\n",
    "plt.title('Non-Linear Yield Response of Maize to July Temperature', fontsize=18)\n",
    "plt.xlabel('Average July Temperature (°C)', fontsize=14)\n",
    "plt.ylabel('Predicted Maize Yield (tonnes per hectare)', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.legend(fontsize=12)\n",
    "plt.ylim(bottom=0)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- VISUALIZATION 2: The Soil Water Response Curve ---\n",
    "print(\"\\nGenerating plot 2: Yield Response to Aggregate Soil Water...\")\n",
    "\n",
    "soil_water_range = np.linspace(df_maize['soil_water'].min(), df_maize['soil_water'].max(), 100)\n",
    "\n",
    "pred_df_sw = pd.DataFrame(mean_values, index=range(100))\n",
    "pred_df_sw['soil_water'] = soil_water_range\n",
    "\n",
    "preds_sw = final_model.get_prediction(pred_df_sw)\n",
    "pred_summary_sw = preds_sw.summary_frame(alpha=0.05)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(pred_df_sw['soil_water'], pred_summary_sw['mean'], color='blue', linewidth=3, label='Predicted Yield')\n",
    "plt.fill_between(pred_df_sw['soil_water'], pred_summary_sw['mean_ci_lower'], pred_summary_sw['mean_ci_upper'], color='blue', alpha=0.2, label='95% Confidence Interval')\n",
    "plt.scatter(df_maize['soil_water'], df_maize['yield_maize'], alpha=0.05, color='gray', label='Raw Data')\n",
    "\n",
    "plt.title('Yield Response of Maize to Aggregate Soil Water', fontsize=18)\n",
    "plt.xlabel('Growing Season Average Soil Water (units)', fontsize=14)\n",
    "plt.ylabel('Predicted Maize Yield (tonnes per hectare)', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.legend(fontsize=12)\n",
    "plt.ylim(bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800d985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---  Generating Vulnerability Curve for Maize ---\")\n",
    "\n",
    "# --- 1. Load Data and Fit the Final Champion Model ---\n",
    "file_path = '../data-cherry-pick/maize_ITnorth_core42_1982_2016_allstressors_with_monthly.csv'\n",
    "\n",
    "try:\n",
    "    df_maize = pd.read_csv(file_path)\n",
    "    df_maize = df_maize[df_maize['yield_maize'] > 0].copy() # Ensure positive yield\n",
    "    print(f\"Successfully loaded dataset from: {file_path}\\n\")\n",
    "\n",
    "    # This is our confirmed Final Champion Model for Maize\n",
    "    final_champion_formula = \"yield_maize ~ year + bs(lat, df=4) + bs(lon, df=4) + potential_evaporation_May + soil_water + temperature_Jul + I(temperature_Jul**2) + precipitation_Sep\"\n",
    "\n",
    "    final_model = smf.glm(\n",
    "        formula=final_champion_formula,\n",
    "        data=df_maize,\n",
    "        family=sm.families.Gamma(link=sm.families.links.log())\n",
    "    ).fit()\n",
    "    print(f\"Final champion model for maize has been successfully fitted. AIC: {final_model.aic:.2f}\")\n",
    "\n",
    "    # --- 2. Find a Real, Representative Observation for Predictions ---\n",
    "    # Find the single observation closest to the median year and median latitude.\n",
    "    median_year = df_maize['year'].median()\n",
    "    median_lat = df_maize['lat'].median()\n",
    "    closest_idx = ((df_maize['year'] - median_year)**2 + (df_maize['lat'] - median_lat)**2).idxmin()\n",
    "    X_template = df_maize.loc[[closest_idx]].reset_index(drop=True)\n",
    "    print(f\"Using a real observation from index {closest_idx} as the template for predictions.\")\n",
    "\n",
    "    # --- 3. Define and Predict the \"Baseline\" Yield ---\n",
    "    # The baseline is the yield at our real template, but with temp_Jul set to its median value.\n",
    "    X_baseline = X_template.copy()\n",
    "    X_baseline['temperature_Jul'] = df_maize['temperature_Jul'].median()\n",
    "    \n",
    "    baseline_pred = final_model.get_prediction(X_baseline).summary_frame(alpha=0.05)\n",
    "    yield_baseline = baseline_pred['mean'].iloc[0]\n",
    "    print(f\"\\nPredicted baseline yield for a typical case: {yield_baseline:.2f} tonnes/hectare\")\n",
    "    \n",
    "    # --- 4. Predict Yield Across the Range of the Stressor ---\n",
    "    temp_jul_range = np.linspace(df_maize['temperature_Jul'].min(), df_maize['temperature_Jul'].max(), 100)\n",
    "    \n",
    "    # Create the prediction grid by replicating our template and overwriting the stressor\n",
    "    X_stress = pd.concat([X_template] * 100, ignore_index=True)\n",
    "    X_stress['temperature_Jul'] = temp_jul_range\n",
    "\n",
    "    stress_pred = final_model.get_prediction(X_stress).summary_frame(alpha=0.05)\n",
    "    yield_predicted = stress_pred['mean']\n",
    "    yield_ci_lower = stress_pred['mean_ci_lower']\n",
    "    yield_ci_upper = stress_pred['mean_ci_upper']\n",
    "\n",
    "    # --- 5. Calculate Percentage Yield Change ---\n",
    "    # The vulnerability is the percentage change from the baseline yield.\n",
    "    yield_change_pct = ((yield_predicted - yield_baseline) / yield_baseline) * 100\n",
    "    yield_change_lower_pct = ((yield_ci_lower - yield_baseline) / yield_baseline) * 100\n",
    "    yield_change_upper_pct = ((yield_ci_upper - yield_baseline) / yield_baseline) * 100\n",
    "\n",
    "    # --- 6. Plot the Vulnerability Curve ---\n",
    "    print(\"Generating the vulnerability curve plot...\")\n",
    "    \n",
    "    sns.set_style(\"whitegrid\")\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "    ax.plot(temp_jul_range, yield_change_pct, color='red', label='Predicted Yield Change')\n",
    "    ax.fill_between(temp_jul_range, yield_change_lower_pct, yield_change_upper_pct, color='red', alpha=0.2, label='95% Confidence Interval')\n",
    "    ax.axhline(0, color='black', linestyle='--', linewidth=0.8)\n",
    "\n",
    "    ax.set_title('Vulnerability of Maize Yield to July Temperature', fontsize=18)\n",
    "    ax.set_xlabel('Average July Temperature (°C)', fontsize=12)\n",
    "    ax.set_ylabel('Yield Change vs. Typical Year (%)', fontsize=12)\n",
    "    ax.legend()\n",
    "    \n",
    "    ax.yaxis.set_major_formatter(PercentFormatter())\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at the specified path: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2f86c6",
   "metadata": {},
   "source": [
    "### **Final Maize Model: Interpretation and Conclusions**\n",
    "\n",
    "This section summarizes the final champion model developed to explain the relationship between monthly climate stressors and maize yield in Northern Italy. The model is the result of a  multi-step workflow designed to be statistically robust, parsimonious, and interpretable.\n",
    "\n",
    "#### **The Final Champion Model**\n",
    "\n",
    "After a data-driven process of variable selection and iterative refinement, the final, best-performing model was determined to be a Gamma GLM with the following structure:\n",
    "\n",
    "**Final Model Formula:**\n",
    "```\n",
    "yield_maize ~ year + bs(lat, df=4) + bs(lon, df=4) + potential_evaporation_May + soil_water + temperature_Jul + I(temperature_Jul**2) + precipitation_Sep\n",
    "```\n",
    "\n",
    "**Key Performance Metrics:**\n",
    "*   **Akaike Information Criterion (AIC):** `5309.83` (The lowest of all tested models)\n",
    "*   **Pseudo R-squared (CS):** `0.8755` (Explains approx. **87.6%** of the variation in yield)\n",
    "\n",
    "#### **The Modeling Journey: How We Arrived Here**\n",
    "\n",
    "The final model was not assumed but was systematically built and validated:\n",
    "\n",
    "1.  **Variable Selection:** An **Elastic Net regularization** was used on a full model to overcome severe multicollinearity. This process objectively identified a small set of robust predictors (`year`, spatial splines, `potential_evaporation_May`, `soil_water`, `temperature_Jul`, `precipitation_Sep`, and `precipitation_Jun`).\n",
    "\n",
    "2.  **Model Refinement (Parsimony):** An initial base model was fitted, and the non-significant `precipitation_Jun` term was removed, resulting in a simpler model with an improved AIC score.\n",
    "\n",
    "3.  **Testing for Non-Linearity:** Guided by strong evidence from our EDA, we tested for a non-linear effect of `temperature_Jul`. Adding a quadratic term (`I(temperature_Jul**2)`) resulted in a **massive drop in AIC**, confirming a critical non-linear relationship. Further tests for non-linearity in other variables (e.g., `precipitation_Sep`) did not improve the model and were rejected.\n",
    "\n",
    "4.  **Testing for Interactions & Alternatives:** We tested the most agronomically plausible interaction (`temperature_Jul:soil_water`), which was not significant and worsened the model's AIC. A sensitivity analysis also confirmed that the aggregate `soil_water` variable was a much stronger predictor than any individual monthly soil water variable.\n",
    "\n",
    "This structured process ensures our final model is not overfit and that every included term is statistically justified and meaningful.\n",
    "\n",
    "#### **Detailed Interpretation of the Final Model**\n",
    "\n",
    "*   **Control Variables:**\n",
    "    *   `year`: The positive, significant coefficient confirms a strong **technological trend**, with yields consistently increasing over time.\n",
    "    *   `bs(lat, df=4)` & `bs(lon, df=4)`: The high significance of the spatial splines confirms that **geography is a dominant driver** of yield, likely due to underlying soil and landscape characteristics.\n",
    "\n",
    "*   **Key Climate Drivers:**\n",
    "    *   `soil_water` & `precipitation_Sep`: These terms both have significant positive coefficients, highlighting the critical importance of **water availability** for maize. The model confirms that a wetter growing season and sufficient late-season rain for grain-filling lead to higher yields.\n",
    "    *   `potential_evaporation_May`: This has a positive coefficient, suggesting that higher evaporative demand in May (a proxy for sunny and warm conditions) is beneficial for early-stage crop establishment.\n",
    "    *   `temperature_Jul` & `I(temperature_Jul**2)`: This is the most important climate finding. The combination of a positive linear term and a significant negative quadratic term confirms a non-linear, **inverted U-shaped response**. This indicates that while warming is initially beneficial, there is an optimal temperature for maize in July. Beyond this peak, higher temperatures become increasingly damaging, a clear statistical signature of **heat stress** during the critical pollination period.\n",
    "\n",
    "#### **Insights from Visualization**\n",
    "\n",
    "*   **The Temperature Response Curve:** The yield response plot for `temperature_Jul` visually confirms the heat stress effect. For the range of data observed in Northern Italy, the curve is almost entirely on the downward-sloping side of the inverted U. This reveals that the primary threat in this region is from temperatures being **too hot, not too cold**, during July.\n",
    "\n",
    "*   **The Soil Water Response Curve:** This plot shows a clear and consistent positive relationship. It visually confirms that higher average soil water throughout the season is strongly associated with higher predicted yields, underscoring the crop's fundamental need for water.\n",
    "\n",
    "*   **The Final Vulnerability Curve:** This plot synthesizes the temperature finding into a quantitative measure of risk. It shows that:\n",
    "    *   **Opportunity:** A cool July (e.g., 15°C) can lead to a **yield gain of over 25%** compared to a typical year.\n",
    "    *   **Vulnerability:** A hot July (e.g., 25°C) can lead to a **yield loss of over -20%**. In an extreme heatwave year (>27°C), losses can exceed **-30%**.\n",
    "\n",
    "#### **Overall Conclusion**\n",
    "\n",
    "The model provides a powerful and statistically robust explanation of maize yield vulnerability in Northern Italy. The dominant story is the dual importance of **heat and water**. While consistent water availability provides a strong foundation for high yields, the ultimate determining factor for year-to-year success or failure is **heat stress during the critical pollination month of July**. The model successfully quantifies this non-linear vulnerability, providing a clear and actionable insight into the primary climate risk facing maize production in the region."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climarisc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
