{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d2fd42",
   "metadata": {},
   "source": [
    "# EDA for Soybean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bcb4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import scipy.stats as stats\n",
    "from patsy import dmatrices\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fbf69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis - Full Correlation Matrix\n",
    "\n",
    "print(\"--- EDA: Correlation Analysis of All Monthly Stressors ---\")\n",
    "\n",
    "# --- 1. Load the Data ---\n",
    "# As confirmed, this file is already specific to soybean and its growing season.\n",
    "file_path = '../data-cherry-pick/soybean_ITnorth_core41_1982_2016_allstressors_with_monthly.csv'\n",
    "\n",
    "try:\n",
    "    df_soybean = pd.read_csv(file_path)\n",
    "    print(f\"Successfully loaded dataset from: {file_path}\")\n",
    "\n",
    "    # --- 2. Select Only the Monthly Stressor Variables ---\n",
    "    # We will select all columns that have a month name in them, which is a robust\n",
    "    # way to grab all the monthly predictors we want to investigate.\n",
    "    monthly_stressors = [col for col in df_soybean.columns if '_' in col and 'yield' not in col]\n",
    "    df_corr = df_soybean[monthly_stressors]\n",
    "    \n",
    "    print(f\"\\nSelected {len(df_corr.columns)} monthly stressor variables for correlation analysis.\")\n",
    "\n",
    "    # --- 3. Calculate and Print the Correlation Matrix ---\n",
    "    correlation_matrix = df_corr.corr()\n",
    "    \n",
    "    # Optional: If you want to see the full numerical matrix, uncomment the next line\n",
    "    # print(\"\\n--- Full Pairwise Correlation Matrix ---\")\n",
    "    # print(correlation_matrix)\n",
    "\n",
    "    # --- 4. Visualize the Matrix with a Heatmap ---\n",
    "    # A heatmap is the best way to see the broad patterns of collinearity.\n",
    "    print(\"\\nGenerating correlation heatmap...\")\n",
    "    \n",
    "    plt.figure(figsize=(18, 15))\n",
    "    heatmap = sns.heatmap(\n",
    "        correlation_matrix,\n",
    "        cmap='coolwarm',  # Use a diverging colormap (red=positive, blue=negative)\n",
    "        center=0,         # Center the colormap at zero\n",
    "        vmin=-1,          # Set the color scale limits to the theoretical min/max\n",
    "        vmax=1,\n",
    "        linewidths=.5,\n",
    "        annot=False       # Annotations are turned off as the matrix is too large to be readable\n",
    "    )\n",
    "    \n",
    "    plt.title('Pairwise Correlation Matrix of All Monthly Stressors for soybean', fontsize=20)\n",
    "    plt.show()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at the specified path: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e3fb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Extended EDA for Soybean Yield Analysis ---\")\n",
    "\n",
    "# --- 1. Load the Data ---\n",
    "file_path = '../data-cherry-pick/soybean_ITnorth_core41_1982_2016_allstressors_with_monthly.csv'\n",
    "\n",
    "try:\n",
    "    df_soybean = pd.read_csv(file_path)\n",
    "    print(f\"Successfully loaded dataset from: {file_path}\\n\")\n",
    "\n",
    "    # --- Task 1: Examine the Distribution of the Dependent Variable (yield_soybean) ---\n",
    "    print(\"--- Task 1: Analyzing the distribution of the dependent variable 'yield_soybean' ---\")\n",
    "    \n",
    "    # Create a figure with two subplots side-by-side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    fig.suptitle('Distribution Analysis for yield_soybeane', fontsize=16)\n",
    "\n",
    "    # a) Histogram with a Kernel Density Estimate (KDE)\n",
    "    # This helps us visually assess the shape, center, and spread of the yield data.\n",
    "    # We are checking for positive skewness, which is characteristic of data modeled by a Gamma distribution.\n",
    "    sns.histplot(df_soybean['yield_soybean'], kde=True, ax=axes[0])\n",
    "    axes[0].set_title('Histogram of Soybean Yield')\n",
    "    axes[0].set_xlabel('Yield (tonnes per hectare)')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "\n",
    "    # b) Q-Q (Quantile-Quantile) Plot against a theoretical normal distribution\n",
    "    # This plot helps us assess if the data's distribution follows a specific theoretical distribution.\n",
    "    # Deviations from the red line suggest skewness or heavy tails.\n",
    "    # While our target is a Gamma GLM, a Q-Q plot vs. Normal is a standard first step to detect non-normality.\n",
    "    stats.probplot(df_soybean['yield_soybean'], dist=\"norm\", plot=axes[1])\n",
    "    axes[1].set_title('Q-Q Plot of Soybean Yield vs. Normal Distribution')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "    print(\"Distribution plots generated. Check for positive skew, which supports our choice of a Gamma GLM.\\n\")\n",
    "\n",
    "\n",
    "    # --- Task 2: Bivariate Scatter Plots of Yield vs. Key Stressors ---\n",
    "    print(\"--- Task 2: Visualizing relationships between yield and key climate stressors ---\")\n",
    "    \n",
    "    # Select a few key stressors based on agronomic theory for soybean\n",
    "    key_stressors = ['temperature_Jul', 'precipitation_Jun', 'soil_water_Aug']\n",
    "    \n",
    "    # Create a figure to hold the scatter plots\n",
    "    fig, axes = plt.subplots(1, len(key_stressors), figsize=(21, 6))\n",
    "    fig.suptitle('Bivariate Relationships: Soybean Yield vs. Key Stressors', fontsize=16)\n",
    "\n",
    "    for i, stressor in enumerate(key_stressors):\n",
    "        # We use a regression plot with a LOWESS (Locally Weighted Scatterplot Smoothing) curve.\n",
    "        # This is a non-parametric way to see the underlying trend without assuming a linear relationship.\n",
    "        # It's excellent for spotting potential non-linearities (like an inverted 'U' shape).\n",
    "        sns.regplot(\n",
    "            x=stressor,\n",
    "            y='yield_soybean',\n",
    "            data=df_soybean,\n",
    "            ax=axes[i],\n",
    "            lowess=True, # Use LOWESS smoother to detect non-linear patterns\n",
    "            scatter_kws={'alpha': 0.1, 'color': 'gray'}, # De-emphasize individual points\n",
    "            line_kws={'color': 'blue'} # Emphasize the trend line\n",
    "        )\n",
    "        axes[i].set_title(f'Yield vs. {stressor}')\n",
    "        axes[i].set_xlabel(f'{stressor}')\n",
    "        axes[i].set_ylabel('Yield (tonnes per hectare)')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "    print(\"Scatter plots generated. Look for non-linear patterns that might inform our final model.\\n\")\n",
    "\n",
    "\n",
    "    # --- Task 3: Plot Key Variables Over Time ---\n",
    "    print(\"--- Task 3: Examining long-term trends in yield and a key climate variable ---\")\n",
    "    \n",
    "    # Calculate the mean of yield and a key stressor for each year\n",
    "    yearly_data = df_soybean.groupby('year')[['yield_soybean', 'temperature_Jul']].mean().reset_index()\n",
    "\n",
    "    # Create a plot with a primary and secondary y-axis to show both trends together.\n",
    "    # This confirms the necessity of including 'year' as a control variable to capture trends\n",
    "    # likely related to technology, while also checking for climate trends.\n",
    "    fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "    # Plotting average yield on the primary (left) y-axis\n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Year')\n",
    "    ax1.set_ylabel('Average Yield (tonnes per hectare)', color=color)\n",
    "    ax1.plot(yearly_data['year'], yearly_data['yield_soybean'], color=color, marker='o', label='Average Yield')\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    # Create a second y-axis that shares the same x-axis\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    # Plotting average temperature on the secondary (right) y-axis\n",
    "    color = 'tab:red'\n",
    "    ax2.set_ylabel('Average July Temperature (°C)', color=color)\n",
    "    ax2.plot(yearly_data['year'], yearly_data['temperature_Jul'], color=color, linestyle='--', marker='x', label='Avg. July Temp')\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    plt.title('Long-Term Trend of Soybean Yield and July Temperature (1982-2016)', fontsize=16)\n",
    "    fig.tight_layout()\n",
    "    # Adding a single legend for both lines\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "    \n",
    "    plt.show()\n",
    "    print(\"Time-series plot generated. Note the clear upward trend in yield, confirming the need for a 'year' control variable.\\n\")\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at the specified path: {file_path}\")\n",
    "except KeyError as e:\n",
    "    print(f\"ERROR: A required column was not found in the dataset: {e}. Please check the CSV file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e564c9b",
   "metadata": {},
   "source": [
    "# regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c0a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load the Data ---\n",
    "file_path = '../data-cherry-pick/soybean_ITnorth_core41_1982_2016_allstressors_with_monthly.csv'\n",
    "\n",
    "try:\n",
    "    df_soybean = pd.read_csv(file_path)\n",
    "    print(f\"Successfully loaded dataset from: {file_path}\")\n",
    "\n",
    "    # --- 2. Define the Full Model Formula ---\n",
    "    # Programmatically get all monthly stressor column names\n",
    "    monthly_stressors = [col for col in df_soybean.columns if '_' in col and 'yield' not in col]\n",
    "    \n",
    "    # Join them with '+' to create the predictor part of the formula\n",
    "    stressor_formula_part = ' + '.join(monthly_stressors)\n",
    "    \n",
    "    # Construct the complete R-style formula string.\n",
    "    # We include our controls (year, spatial splines) and all potential predictors.\n",
    "    # Note: patsy's bs() function creates the basis spline columns.\n",
    "    formula = f\"yield_soybean ~ year + bs(lat, df=4) + bs(lon, df=4) + {stressor_formula_part}\"\n",
    "    \n",
    "    print(\"\\nGenerated model formula for patsy:\")\n",
    "    print(formula) # Uncomment to see the full, very long formula string\n",
    "\n",
    "    # --- 3. Create the Design Matrix (X) and Response Vector (y) ---\n",
    "    # patsy processes the formula and the dataframe to create the matrices needed for modeling.\n",
    "    # 'y' will be our dependent variable, 'X' will be the full set of predictors.\n",
    "    # The intercept is automatically included in 'X' by patsy.\n",
    "    print(\"\\nCreating design matrix (X) and response vector (y) using patsy...\")\n",
    "    y, X = dmatrices(formula, data=df_soybean, return_type='dataframe')\n",
    "    \n",
    "    print(f\"Successfully created response vector y with shape: {y.shape}\")\n",
    "    print(f\"Successfully created design matrix X with shape: {X.shape}\")\n",
    "    print(f\"The {X.shape[1]} columns in X include the intercept, year, 8 spline bases (4 for lat, 4 for lon), and {len(monthly_stressors)} climate stressors.\")\n",
    "\n",
    "    # --- 4. Standardize the Predictor Matrix (X) ---\n",
    "    # We scale ALL predictors to have a mean of 0 and a standard deviation of 1.\n",
    "    # This ensures the regularization penalty is applied fairly to all variables.\n",
    "    # We do NOT scale the response variable y.\n",
    "    print(\"\\nStandardizing the design matrix X...\")\n",
    "    \n",
    "    # We remove the Intercept column before scaling, as it should not be regularized or scaled.\n",
    "    # We will add it back later if needed, but scikit-learn's models handle it by default.\n",
    "    X_no_intercept = X.drop('Intercept', axis=1)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled_values = scaler.fit_transform(X_no_intercept)\n",
    "    \n",
    "    # Convert the scaled array back to a pandas DataFrame with the original column names\n",
    "    X_scaled = pd.DataFrame(X_scaled_values, columns=X_no_intercept.columns, index=X.index)\n",
    "    \n",
    "    print(\"Standardization complete.\")\n",
    "    \n",
    "    # Verification: Check the mean and standard deviation of a few scaled columns\n",
    "    print(\"\\n--- Verification of Standardization ---\")\n",
    "    verification_cols = ['year', 'bs(lat, df=4)[0]', 'temperature_Jul']\n",
    "    for col in verification_cols:\n",
    "        mean_val = X_scaled[col].mean()\n",
    "        std_val = X_scaled[col].std()\n",
    "        print(f\"Column '{col}': Mean = {mean_val:.4f}, Std Dev = {std_val:.4f}\")\n",
    "    print(\"------------------------------------\")\n",
    "    \n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at the specified path: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9905bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume 'y' and 'X_scaled' are already in memory from the previous step.\n",
    "# If not, you would need to re-run the data preparation script.\n",
    "\n",
    "try:\n",
    "    # --- 1. Define the GLM Model ---\n",
    "    # We specify our model family (Gamma) and the link function (log) as per our project plan.\n",
    "    # We pass the prepared y and the fully scaled X matrix.\n",
    "    # Note: statsmodels requires the intercept to be in the X matrix, which patsy provided.\n",
    "    \n",
    "    # We need to add the intercept back to the scaled data for statsmodels GLM\n",
    "    X_scaled_with_intercept = X.copy() # Start with the original X to preserve intercept and structure\n",
    "    X_scaled_with_intercept[X_no_intercept.columns] = X_scaled # Replace non-intercept columns with scaled versions\n",
    "\n",
    "    gl_gamma = sm.GLM(y, X_scaled_with_intercept, family=sm.families.Gamma(link=sm.families.links.log()))\n",
    "    print(\"Successfully initialized Gamma GLM with a log link.\")\n",
    "\n",
    "    # --- 2. Set up the Regularization Path ---\n",
    "    # We need to test a series of alpha values (penalty strengths).\n",
    "    # A logarithmic scale is best for this, from a weak penalty to a strong one.\n",
    "    n_alphas = 100\n",
    "    alphas = np.logspace(-3, 0.5, n_alphas) # From 0.001 to ~3.16\n",
    "\n",
    "    # The L1_wt parameter controls the Elastic Net mix (0=Ridge, 1=Lasso). \n",
    "    # 0.5 is a balanced choice.\n",
    "    elastic_net_l1_wt = 0.5 \n",
    "    \n",
    "    print(f\"Will fit the model for {n_alphas} alpha values with L1_wt (l1_ratio) = {elastic_net_l1_wt}\")\n",
    "\n",
    "    # --- 3. Fit the Model for Each Alpha and Store Coefficients ---\n",
    "    # We will loop through our alphas and save the coefficients from each model fit.\n",
    "    coefficients = []\n",
    "    \n",
    "    for alpha_val in alphas:\n",
    "        # The fit_regularized method performs the Elastic Net estimation.\n",
    "        # We set refit=False because we want to see the shrunken coefficients for this analysis.\n",
    "        results = gl_gamma.fit_regularized(\n",
    "            method='elastic_net', \n",
    "            alpha=alpha_val, \n",
    "            L1_wt=elastic_net_l1_wt,\n",
    "            refit=False \n",
    "        )\n",
    "        coefficients.append(results.params)\n",
    "    \n",
    "    # Convert the list of coefficient series into a DataFrame for easy plotting\n",
    "    coef_df = pd.DataFrame(coefficients, index=alphas)\n",
    "    coef_df.index.name = \"alpha\"\n",
    "    \n",
    "    # Exclude the Intercept for plotting, as it's not regularized and has a different scale.\n",
    "    coef_df_no_intercept = coef_df.drop('Intercept', axis=1)\n",
    "    \n",
    "    print(\"\\nCompleted fitting models along the regularization path.\")\n",
    "\n",
    "    # --- 4. Visualize the Regularization Path ---\n",
    "    print(\"Generating the regularization path plot...\")\n",
    "    \n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(16, 10))\n",
    "\n",
    "    ax.plot(coef_df_no_intercept)\n",
    "    ax.set_xscale('log') # The alpha path is best viewed on a log scale\n",
    "    \n",
    "    # Add a vertical line at zero\n",
    "    ax.axhline(0, color='black', linewidth=0.5, linestyle='--')\n",
    "    \n",
    "    ax.set_title('Regularization Path for Rice Model Coefficients (Elastic Net)', fontsize=18)\n",
    "    ax.set_xlabel('Alpha (Penalty Strength)', fontsize=14)\n",
    "    ax.set_ylabel('Standardized Coefficient Value', fontsize=14)\n",
    "    \n",
    "    # To avoid a cluttered legend, we don't add one here. The goal is to see the general pattern.\n",
    "    # Alternatively, for fewer variables, a legend could be useful:\n",
    "    # ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "except NameError:\n",
    "    print(\"ERROR: Make sure that 'y' and 'X_scaled' DataFrames from the previous step are available in memory.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8627f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Corrected code to identify the most robust variables ---\n",
    "# We will inspect the coefficients at a moderately high alpha value\n",
    "# This tells us which variables \"survived\" the penalty the longest.\n",
    "alpha_to_inspect = 0.03 \n",
    "\n",
    "try:\n",
    "    # Find the alpha in our index that is closest to our target\n",
    "    # CORRECTED LINE: The operation works directly on the index without .flat\n",
    "    closest_alpha = coef_df.index[np.abs(coef_df.index - alpha_to_inspect).argmin()]\n",
    "\n",
    "    print(f\"--- Coefficients at alpha ≈ {closest_alpha:.4f} ---\")\n",
    "\n",
    "    # Get the coefficients at this alpha and sort them by absolute value\n",
    "    robust_coeffs = coef_df.loc[closest_alpha].copy()\n",
    "    robust_coeffs_sorted = robust_coeffs.abs().sort_values(ascending=False)\n",
    "\n",
    "    print(\"\\nVariables sorted by the absolute magnitude of their shrunken coefficient:\")\n",
    "    # We display more variables to get a fuller picture\n",
    "    print(robust_coeffs_sorted.head(15))\n",
    "\n",
    "    # Let's also see their actual values (positive or negative) for the top variables\n",
    "    print(\"\\n--- Actual coefficient values for the most robust variables ---\")\n",
    "    print(coef_df.loc[closest_alpha, robust_coeffs_sorted.index].head(10))\n",
    "\n",
    "except NameError:\n",
    "     print(\"ERROR: Make sure that 'coef_df' DataFrame from the previous step is available in memory.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df12c813",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b113c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Fitting the Base Champion Model ---\")\n",
    "\n",
    "# --- 1. Load the Data ---\n",
    "# We use the original dataframe for this step.\n",
    "file_path = '../data-cherry-pick/soybean_ITnorth_core41_1982_2016_allstressors_with_monthly.csv'\n",
    "\n",
    "try:\n",
    "    df_soybean = pd.read_csv(file_path)\n",
    "    print(f\"Successfully loaded dataset from: {file_path}\\n\")\n",
    "\n",
    "    # --- 2. Define and Fit the Champion Model ---\n",
    "    # This formula contains only the variables that proved robust in the regularization step.\n",
    "    # We use statsmodels.formula.api which simplifies fitting models from a formula string.\n",
    "    champion_formula = \"yield_soybean ~ year + bs(lat, df=4) + bs(lon, df=4) + potential_evaporation_May + solar_radiation_Jul + soil_water + precipitation_May\"\n",
    "\n",
    "    # Initialize the GLM model using the formula and the dataframe.\n",
    "    # Specify the Gamma family with a log link as planned.\n",
    "    base_model = smf.glm(\n",
    "        formula=champion_formula,\n",
    "        data=df_soybean,\n",
    "        family=sm.families.Gamma(link=sm.families.links.log())\n",
    "    )\n",
    "\n",
    "    # Fit the model. This is the standard, un-penalized fit.\n",
    "    base_model_results = base_model.fit()\n",
    "\n",
    "    # --- 3. Print the Full Summary for Interpretation ---\n",
    "    # This summary is now statistically valid and is the basis for our interpretation.\n",
    "    print(\"--- Summary of the Base Champion Model ---\")\n",
    "    print(base_model_results.summary())\n",
    "\n",
    "    # --- 4. Print AIC for Future Comparison ---\n",
    "    # The AIC is a key metric for comparing different model formulations. Lower is better.\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"AIC for Base Champion Model: {base_model_results.aic:.2f}\")\n",
    "    print(\"This will be our benchmark for comparison.\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at the specified path: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9131c6b1",
   "metadata": {},
   "source": [
    "## non linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74415eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Testing for Non-Linearity (Quadratic Term for solar_rad_Jul) ---\")\n",
    "\n",
    "# --- 1. Load the Data ---\n",
    "file_path = '../data-cherry-pick/soybean_ITnorth_core41_1982_2016_allstressors_with_monthly.csv'\n",
    "\n",
    "try:\n",
    "    df_soybean = pd.read_csv(file_path)\n",
    "    print(f\"Successfully loaded dataset from: {file_path}\\n\")\n",
    "\n",
    "    # --- 2. Define and Fit the Model with the Quadratic Term ---\n",
    "    # We build on our simplified champion by adding a squared term for solar_radiation_Jul.\n",
    "    # This directly tests the inverted U-shape hypothesis from our EDA.\n",
    "    quadratic_formula = \"yield_soybean ~ year + bs(lat, df=4) + bs(lon, df=4) + potential_evaporation_May + solar_radiation_Jul + soil_water + precipitation_May + I(solar_radiation_Jul**2)\"\n",
    "\n",
    "    # Initialize the GLM model using the new quadratic formula.\n",
    "    quadratic_model = smf.glm(\n",
    "        formula=quadratic_formula,\n",
    "        data=df_soybean,\n",
    "        family=sm.families.Gamma(link=sm.families.links.log())\n",
    "    )\n",
    "\n",
    "    # Fit the model.\n",
    "    quadratic_model_results = quadratic_model.fit()\n",
    "\n",
    "    # --- 3. Print the Full Summary for Interpretation ---\n",
    "    print(\"--- Summary of the Model with Quadratic Term ---\")\n",
    "    print(quadratic_model_results.summary())\n",
    "\n",
    "    # --- 4. Print AIC for Comparison ---\n",
    "    # We will compare this AIC to our current champion's AIC (3516.86).\n",
    "    # A lower AIC will indicate that capturing the non-linear effect is an improvement.\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"AIC for Quadratic Model: {quadratic_model_results.aic:.2f}\")\n",
    "    print(\"Compare this to the Simplified Base Model's AIC (3516.86).\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at the specified path: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509f35d1",
   "metadata": {},
   "source": [
    "## interpreatation\n",
    "\n",
    "This model fails compleatly. Something breaks in the internal fitting process, and I think this is probs cause of multicolineariity introduced by the quadratic term, and the instense numerical variables of the solar radiation columns. So the idea is that if we standardize the solar radiation columns, this should fix the problem. \n",
    "\n",
    "We are doing z score standardization. It does two things: it centers the variable at zero AND it scales it to have a standard deviation of 1. This is like what we did when we standardized all our variables for regularization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff5e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Testing for Non-Linearity (Quadratic Term for solar_rad_Jul) ---\")\n",
    "\n",
    "# --- 1. Load the Data ---\n",
    "file_path = '../data-cherry-pick/soybean_ITnorth_core41_1982_2016_allstressors_with_monthly.csv'\n",
    "\n",
    "try:\n",
    "    df_soybean = pd.read_csv(file_path)\n",
    "    print(f\"Successfully loaded dataset from: {file_path}\\n\")\n",
    "\n",
    "    df_soybean[\"solar_rad_Jul_z\"] = (\n",
    "    df_soybean[\"solar_radiation_Jul\"] - df_soybean[\"solar_radiation_Jul\"].mean()\n",
    "    ) / df_soybean[\"solar_radiation_Jul\"].std()\n",
    "\n",
    "\n",
    "    # --- 2. Define and Fit the Model with the Quadratic Term ---\n",
    "    # We build on our simplified champion by adding a squared term for solar_radiation_Jul.\n",
    "    # This directly tests the inverted U-shape hypothesis from our EDA.\n",
    "    quadratic_formula = \"\"\"\n",
    "    yield_soybean ~ year + bs(lat, df=4) + bs(lon, df=4) +\n",
    "                    potential_evaporation_May + solar_rad_Jul_z +\n",
    "                    soil_water + precipitation_May +\n",
    "                    I(solar_rad_Jul_z**2)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Initialize the GLM model using the new quadratic formula.\n",
    "    quadratic_model = smf.glm(\n",
    "        formula=quadratic_formula,\n",
    "        data=df_soybean,\n",
    "        family=sm.families.Gamma(link=sm.families.links.log())\n",
    "    )\n",
    "\n",
    "    # Fit the model.\n",
    "    quadratic_model_results = quadratic_model.fit()\n",
    "\n",
    "    # --- 3. Print the Full Summary for Interpretation ---\n",
    "    print(\"--- Summary of the Model with Quadratic Term ---\")\n",
    "    print(quadratic_model_results.summary())\n",
    "\n",
    "    # --- 4. Print AIC for Comparison ---\n",
    "    # We will compare this AIC to our current champion's AIC (3516.86).\n",
    "    # A lower AIC will indicate that capturing the non-linear effect is an improvement.\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"AIC for Quadratic Model: {quadratic_model_results.aic:.2f}\")\n",
    "    print(\"Compare this to the Simplified Base Model's AIC (3516.86).\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at the specified path: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8efb62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Testing for Non-Linearity (Quadratic Term for solar_rad_Jul) ---\")\n",
    "\n",
    "# --- 1. Load the Data ---\n",
    "file_path = '../data-cherry-pick/soybean_ITnorth_core41_1982_2016_allstressors_with_monthly.csv'\n",
    "\n",
    "try:\n",
    "    df_soybean = pd.read_csv(file_path)\n",
    "    print(f\"Successfully loaded dataset from: {file_path}\\n\")\n",
    "\n",
    "    df_soybean[\"solar_rad_Jul_z\"] = (\n",
    "    df_soybean[\"solar_radiation_Jul\"] - df_soybean[\"solar_radiation_Jul\"].mean()\n",
    "    ) / df_soybean[\"solar_radiation_Jul\"].std()\n",
    "\n",
    "\n",
    "    # --- 2. Define and Fit the Model with the Quadratic Term ---\n",
    "    # We build on our simplified champion by adding a squared term for solar_radiation_Jul.\n",
    "    # This directly tests the inverted U-shape hypothesis from our EDA.\n",
    "    second_quadratic_formula = \"\"\"\n",
    "    yield_soybean ~ year + bs(lat, df=4) + bs(lon, df=4) +\n",
    "                    potential_evaporation_May + solar_rad_Jul_z +\n",
    "                    soil_water + precipitation_May +\n",
    "                    I(solar_rad_Jul_z**2) + I(precipitation_May**2)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Initialize the GLM model using the new quadratic formula.\n",
    "    second_quadratic_model = smf.glm(\n",
    "        formula=second_quadratic_formula,\n",
    "        data=df_soybean,\n",
    "        family=sm.families.Gamma(link=sm.families.links.log())\n",
    "    )\n",
    "\n",
    "    # Fit the model.\n",
    "    second_quadratic_model_results = second_quadratic_model.fit()\n",
    "\n",
    "    # --- 3. Print the Full Summary for Interpretation ---\n",
    "    print(\"--- Summary of the Model with Quadratic Term ---\")\n",
    "    print(second_quadratic_model_results.summary())\n",
    "\n",
    "    # --- 4. Print AIC for Comparison ---\n",
    "    # We will compare this AIC to our current champion's AIC (3496.83).\n",
    "    # A lower AIC will indicate that capturing the non-linear effect is an improvement.\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"AIC for Quadratic Model: {second_quadratic_model_results.aic:.2f}\")\n",
    "    print(\"Compare this to the Simplified Base Model's AIC (3496.83).\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at the specified path: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54f83e9",
   "metadata": {},
   "source": [
    "## interractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7f38b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Testing for interractions ---\")\n",
    "\n",
    "# --- 1. Load the Data ---\n",
    "file_path = '../data-cherry-pick/soybean_ITnorth_core41_1982_2016_allstressors_with_monthly.csv'\n",
    "\n",
    "try:\n",
    "    df_soybean = pd.read_csv(file_path)\n",
    "    print(f\"Successfully loaded dataset from: {file_path}\\n\")\n",
    "\n",
    "    df_soybean[\"solar_rad_Jul_z\"] = (\n",
    "    df_soybean[\"solar_radiation_Jul\"] - df_soybean[\"solar_radiation_Jul\"].mean()\n",
    "    ) / df_soybean[\"solar_radiation_Jul\"].std()\n",
    "\n",
    "\n",
    "    # --- 2. Define and Fit the Model with the interraction ---\n",
    "    interraction_formula = \"\"\"\n",
    "    yield_soybean ~ year + bs(lat, df=4) + bs(lon, df=4) +\n",
    "                    potential_evaporation_May + solar_rad_Jul_z +\n",
    "                    soil_water + precipitation_May +\n",
    "                    I(solar_rad_Jul_z**2) + I(precipitation_May**2)\n",
    "                    + solar_rad_Jul_z:soil_water + potential_evaporation_May:solar_rad_Jul_z\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Initialize the GLM model using the new quadratic formula.\n",
    "    interraction_model = smf.glm(\n",
    "        formula=interraction_formula,\n",
    "        data=df_soybean,\n",
    "        family=sm.families.Gamma(link=sm.families.links.log())\n",
    "    )\n",
    "\n",
    "    # Fit the model.\n",
    "    interraction_model_results = interraction_model.fit()\n",
    "\n",
    "    # --- 3. Print the Full Summary for Interpretation ---\n",
    "    print(\"--- Summary of the Model with interraction Term ---\")\n",
    "    print(interraction_model_results.summary())\n",
    "\n",
    "    # --- 4. Print AIC for Comparison ---\n",
    "    # We will compare this AIC to our current champion's AIC (3487.03).\n",
    "    # A lower AIC will indicate that capturing the non-linear effect is an improvement.\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"AIC for Quadratic Model: {interraction_model_results.aic:.2f}\")\n",
    "    print(\"Compare this to the Simplified Base Model's AIC (3487.03).\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at the specified path: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1728e162",
   "metadata": {},
   "source": [
    "## visaulisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7481e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Generating Final Yield Response Curves for Soybean ---\")\n",
    "\n",
    "# --- 1. Load and Prepare Data ---\n",
    "file_path = '../data-cherry-pick/soybean_ITnorth_core41_1982_2016_allstressors_with_monthly.csv'\n",
    "df_soybean = pd.read_csv(file_path)\n",
    "df_soybean = df_soybean[df_soybean['yield_soybean'] > 0].copy()\n",
    "\n",
    "# Standardize the necessary variables for the model formula\n",
    "df_soybean[\"solar_rad_Jul_z\"] = (df_soybean[\"solar_radiation_Jul\"] - df_soybean[\"solar_radiation_Jul\"].mean()) / df_soybean[\"solar_radiation_Jul\"].std()\n",
    "print(\"Data prepared successfully.\")\n",
    "\n",
    "# --- 2. Fit Our Final Champion Model ---\n",
    "final_champion_formula = \"\"\"\n",
    "    yield_soybean ~ year + bs(lat, df=4) + bs(lon, df=4) +\n",
    "                    potential_evaporation_May + solar_rad_Jul_z +\n",
    "                    soil_water + precipitation_May +\n",
    "                    I(solar_rad_Jul_z**2) + I(precipitation_May**2) +\n",
    "                    solar_rad_Jul_z:soil_water + potential_evaporation_May:solar_rad_Jul_z\n",
    "\"\"\"\n",
    "print(\"Fitting Final Champion model for Soybean...\")\n",
    "final_model = smf.glm(\n",
    "    formula=final_champion_formula,\n",
    "    data=df_soybean,\n",
    "    family=sm.families.Gamma(link=sm.families.links.log())\n",
    ").fit()\n",
    "print(f\"Model fitted successfully. AIC: {final_model.aic:.2f}\")\n",
    "\n",
    "\n",
    "# --- 3. Prepare a Base Prediction Dictionary with Median Values ---\n",
    "median_values = {\n",
    "    'year': df_soybean['year'].median(),\n",
    "    'lat': df_soybean['lat'].median(),\n",
    "    'lon': df_soybean['lon'].median(),\n",
    "    'potential_evaporation_May': df_soybean['potential_evaporation_May'].median(),\n",
    "    'solar_rad_Jul_z': df_soybean['solar_rad_Jul_z'].median(), # Use the standardized variable\n",
    "    'soil_water': df_soybean['soil_water'].median(),\n",
    "    'precipitation_May': df_soybean['precipitation_May'].median()\n",
    "}\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "# --- PLOT A: Yield Response to Soil Water ---\n",
    "print(\"\\nGenerating Plot A: Yield Response to Soil Water...\")\n",
    "soil_water_range = np.linspace(df_soybean['soil_water'].min(), df_soybean['soil_water'].max(), 100)\n",
    "pred_df_sw = pd.DataFrame(median_values, index=range(100))\n",
    "pred_df_sw['soil_water'] = soil_water_range\n",
    "\n",
    "preds_sw = final_model.get_prediction(pred_df_sw).summary_frame(alpha=0.05)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(pred_df_sw['soil_water'], preds_sw['mean'], color='blue', linewidth=3, label='Predicted Yield')\n",
    "plt.fill_between(pred_df_sw['soil_water'], preds_sw['mean_ci_lower'], preds_sw['mean_ci_upper'], color='blue', alpha=0.2, label='95% Confidence Interval')\n",
    "plt.title('Yield Response of Soybean to Aggregate Soil Water', fontsize=18)\n",
    "plt.xlabel('Growing Season Average Soil Water (units)', fontsize=14)\n",
    "plt.ylabel('Predicted Soybean Yield (tonnes per hectare)', fontsize=14)\n",
    "plt.legend(); plt.ylim(bottom=0); plt.show()\n",
    "\n",
    "\n",
    "# --- PLOT B: Non-Linear Yield Response to July Solar Radiation ---\n",
    "print(\"\\nGenerating Plot B: Non-Linear Yield Response to July Solar Radiation...\")\n",
    "solar_jul_z_range = np.linspace(df_soybean['solar_rad_Jul_z'].min(), df_soybean['solar_rad_Jul_z'].max(), 100)\n",
    "pred_df_solar = pd.DataFrame(median_values, index=range(100))\n",
    "pred_df_solar['solar_rad_Jul_z'] = solar_jul_z_range\n",
    "\n",
    "preds_solar = final_model.get_prediction(pred_df_solar).summary_frame(alpha=0.05)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(pred_df_solar['solar_rad_Jul_z'], preds_solar['mean'], color='red', linewidth=3, label='Predicted Yield')\n",
    "plt.fill_between(pred_df_solar['solar_rad_Jul_z'], preds_solar['mean_ci_lower'], preds_solar['mean_ci_upper'], color='red', alpha=0.2, label='95% Confidence Interval')\n",
    "plt.title('Non-Linear Yield Response of Soybean to July Solar Radiation', fontsize=18)\n",
    "plt.xlabel('Standardized July Solar Radiation (Z-score)', fontsize=14)\n",
    "plt.ylabel('Predicted Soybean Yield (tonnes per hectare)', fontsize=14)\n",
    "plt.legend(); plt.ylim(bottom=0); plt.show()\n",
    "\n",
    "\n",
    "# --- PLOT C: Non-Linear Yield Response to May Precipitation ---\n",
    "print(\"\\nGenerating Plot C: Non-Linear Yield Response to May Precipitation...\")\n",
    "precip_may_range = np.linspace(df_soybean['precipitation_May'].min(), df_soybean['precipitation_May'].max(), 100)\n",
    "pred_df_precip = pd.DataFrame(median_values, index=range(100))\n",
    "pred_df_precip['precipitation_May'] = precip_may_range\n",
    "\n",
    "preds_precip = final_model.get_prediction(pred_df_precip).summary_frame(alpha=0.05)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(pred_df_precip['precipitation_May'], preds_precip['mean'], color='green', linewidth=3, label='Predicted Yield')\n",
    "plt.fill_between(pred_df_precip['precipitation_May'], preds_precip['mean_ci_lower'], preds_precip['mean_ci_upper'], color='green', alpha=0.2, label='95% Confidence Interval')\n",
    "plt.title('Non-Linear Yield Response of Soybean to May Precipitation', fontsize=18)\n",
    "plt.xlabel('May Precipitation (mm)', fontsize=14)\n",
    "plt.ylabel('Predicted Soybean Yield (tonnes per hectare)', fontsize=14)\n",
    "plt.legend(); plt.ylim(bottom=0); plt.show()\n",
    "\n",
    "\n",
    "# --- PLOT D: The \"Money Plot\" - Heat x Water Interaction ---\n",
    "print('\\nGenerating Plot D: The \"Heat x Water\" Interaction Effect...')\n",
    "sw_quantiles = df_soybean['soil_water'].quantile([0.25, 0.5, 0.75])\n",
    "scenarios = {\n",
    "    'Drought (25th Pct SW)': {'value': sw_quantiles[0.25], 'color': 'orange'},\n",
    "    'Average (50th Pct SW)': {'value': sw_quantiles[0.50], 'color': 'purple'},\n",
    "    'Wet (75th Pct SW)': {'value': sw_quantiles[0.75], 'color': 'cyan'}\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(14, 9))\n",
    "for scenario_name, props in scenarios.items():\n",
    "    pred_df_interact = pd.DataFrame(median_values, index=range(100))\n",
    "    pred_df_interact['solar_rad_Jul_z'] = solar_jul_z_range # Vary solar radiation on x-axis\n",
    "    pred_df_interact['soil_water'] = props['value'] # Set the soil water for this scenario\n",
    "    \n",
    "    preds_interact = final_model.get_prediction(pred_df_interact).summary_frame(alpha=0.05)\n",
    "    \n",
    "    plt.plot(pred_df_interact['solar_rad_Jul_z'], preds_interact['mean'], color=props['color'], linewidth=3, label=scenario_name)\n",
    "    plt.fill_between(pred_df_interact['solar_rad_Jul_z'], preds_interact['mean_ci_lower'], preds_interact['mean_ci_upper'], color=props['color'], alpha=0.15)\n",
    "\n",
    "plt.title('Vulnerability to July Heat is Amplified by Drought', fontsize=18)\n",
    "plt.xlabel('Standardized July Solar Radiation (Z-score)', fontsize=14)\n",
    "plt.ylabel('Predicted Soybean Yield (tonnes per hectare)', fontsize=14)\n",
    "plt.legend(title='Soil Water Scenario'); plt.ylim(bottom=0); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755e86f6",
   "metadata": {},
   "source": [
    "### **Analysis of Soybean Yield Response Curves**\n",
    "\n",
    "These plots visualize the key relationships from our final, complex statistical model. They show how predicted soybean yield responds to specific climate factors while holding all others at their typical values.\n",
    "\n",
    "#### **Plot A: Yield Response to Aggregate Soil Water**\n",
    "\n",
    "*   **Primary Finding:** Higher average soil water throughout the growing season is consistently associated with higher soybean yields.\n",
    "*   **Interpretation:** The plot shows a clear, strong positive relationship. This confirms that overall water availability is a fundamental driver of yield, which makes perfect agronomic sense as water is a key input for plant growth and seed development.\n",
    "\n",
    "#### **Plot B: Non-Linear Yield Response to July Solar Radiation**\n",
    "\n",
    "*   **Primary Finding:** The model reveals a distinct **inverted U-shape**, indicating an optimal level of solar radiation in July.\n",
    "*   **Interpretation:** Yields peak when standardized solar radiation is slightly below average (around -0.5 Z-score). Beyond this optimum, higher solar radiation (representing \"heat stress\") causes a significant and accelerating decline in yield. This captures the critical vulnerability of soybean during its flowering and pod-setting phase.\n",
    "\n",
    "#### **Plot C: Non-Linear Yield Response to May Precipitation**\n",
    "\n",
    "*   **Primary Finding:** The relationship with May precipitation is also an **inverted U-shape**, showing that both too little and too much rain are suboptimal.\n",
    "*   **Interpretation:** The curve shows that yields are maximized at a moderate level of May rainfall (around 200mm). This suggests that while some rain is essential for crop establishment, excessive rainfall can be detrimental, possibly due to waterlogging or associated cool, cloudy conditions.\n",
    "\n",
    "#### **Plot D: The Interaction of Heat and Water Stress**\n",
    "\n",
    "*   **Primary Finding:** The plant's vulnerability to July heat stress is **strongly mediated by water availability.**\n",
    "*   **Interpretation:** This plot visualizes our most sophisticated finding. The three curves show the yield response to July heat under different soil water scenarios. The \"Wet\" curve (cyan) is consistently higher than the \"Drought\" curve (orange). This visually proves that having ample soil water **increases the overall yield potential** and helps the crop **better tolerate heat stress**, leading to higher yields at any given level of July solar radiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f839c3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Generating Final Vulnerability Curves for Soybean ---\")\n",
    "\n",
    "# --- 1. Load and Prepare Data ---\n",
    "file_path = '../data-cherry-pick/soybean_ITnorth_core41_1982_2016_allstressors_with_monthly.csv'\n",
    "\n",
    "try:\n",
    "    df_soybean = pd.read_csv(file_path)\n",
    "    df_soybean = df_soybean[df_soybean['yield_soybean'] > 0].copy()\n",
    "\n",
    "    # Standardize the necessary variables\n",
    "    df_soybean[\"solar_rad_Jul_z\"] = (df_soybean[\"solar_radiation_Jul\"] - df_soybean[\"solar_radiation_Jul\"].mean()) / df_soybean[\"solar_radiation_Jul\"].std()\n",
    "    print(\"Data prepared successfully.\")\n",
    "\n",
    "    # --- 2. Fit Our Final Champion Model ---\n",
    "    final_champion_formula = \"\"\"\n",
    "        yield_soybean ~ year + bs(lat, df=4) + bs(lon, df=4) +\n",
    "                        potential_evaporation_May + solar_rad_Jul_z +\n",
    "                        soil_water + precipitation_May +\n",
    "                        I(solar_rad_Jul_z**2) + I(precipitation_May**2) +\n",
    "                        solar_rad_Jul_z:soil_water + potential_evaporation_May:solar_rad_Jul_z\n",
    "    \"\"\"\n",
    "    final_model = smf.glm(\n",
    "        formula=final_champion_formula,\n",
    "        data=df_soybean,\n",
    "        family=sm.families.Gamma(link=sm.families.links.log())\n",
    "    ).fit()\n",
    "    print(f\"Final champion model for Soybean fitted successfully. AIC: {final_model.aic:.2f}\\n\")\n",
    "\n",
    "    # --- 3. Define Scenarios and the Baseline ---\n",
    "    # We define our water stress scenarios\n",
    "    sw_quantiles = df_soybean['soil_water'].quantile([0.25, 0.5, 0.75])\n",
    "    scenarios = {\n",
    "        'Drought (25th Pct SW)': {'value': sw_quantiles[0.25], 'color': 'orange'},\n",
    "        'Average (50th Pct SW)': {'value': sw_quantiles[0.50], 'color': 'purple'},\n",
    "        'Wet (75th Pct SW)': {'value': sw_quantiles[0.75], 'color': 'cyan'}\n",
    "    }\n",
    "    \n",
    "    # Our \"typical year\" is an average year for water and an average year for heat\n",
    "    median_values = {\n",
    "        'year': df_soybean['year'].median(),\n",
    "        'lat': df_soybean['lat'].median(),\n",
    "        'lon': df_soybean['lon'].median(),\n",
    "        'potential_evaporation_May': df_soybean['potential_evaporation_May'].median(),\n",
    "        'solar_rad_Jul_z': df_soybean['solar_rad_Jul_z'].median(), # Median (average) heat\n",
    "        'soil_water': df_soybean['soil_water'].median(),      # Median (average) water\n",
    "        'precipitation_May': df_soybean['precipitation_May'].median()\n",
    "    }\n",
    "    X_baseline = pd.DataFrame(median_values, index=[0])\n",
    "    yield_baseline = final_model.get_prediction(X_baseline).summary_frame()['mean'].iloc[0]\n",
    "    print(f\"Predicted baseline yield for a typical case (median heat, median water): {yield_baseline:.2f} t/ha\")\n",
    "\n",
    "    # --- 4. Generate and Plot Vulnerability for Each Scenario ---\n",
    "    print(\"Generating the vulnerability curve plot...\")\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    fig, ax = plt.subplots(figsize=(14, 9))\n",
    "    \n",
    "    solar_jul_z_range = np.linspace(df_soybean['solar_rad_Jul_z'].min(), df_soybean['solar_rad_Jul_z'].max(), 100)\n",
    "\n",
    "    for scenario_name, props in scenarios.items():\n",
    "        # Create the prediction grid for this scenario\n",
    "        pred_df_scenario = pd.DataFrame(median_values, index=range(100))\n",
    "        pred_df_scenario['solar_rad_Jul_z'] = solar_jul_z_range # Vary heat on x-axis\n",
    "        pred_df_scenario['soil_water'] = props['value']     # Set the water level for this scenario\n",
    "        \n",
    "        # Get predictions\n",
    "        preds = final_model.get_prediction(pred_df_scenario).summary_frame(alpha=0.05)\n",
    "        yield_predicted = preds['mean']\n",
    "        \n",
    "        # Calculate percentage change from the single baseline\n",
    "        yield_change_pct = ((yield_predicted - yield_baseline) / yield_baseline) * 100\n",
    "        \n",
    "        # Plot the vulnerability curve for this scenario\n",
    "        ax.plot(solar_jul_z_range, yield_change_pct, color=props['color'], linewidth=3, label=scenario_name)\n",
    "\n",
    "    ax.axhline(0, color='black', linestyle='--', linewidth=0.8)\n",
    "    ax.set_title('Vulnerability of Soybean Yield to July Heat, by Water Availability', fontsize=18)\n",
    "    ax.set_xlabel('Standardized July Solar Radiation (Z-score)', fontsize=14)\n",
    "    ax.set_ylabel('Yield Change vs. Typical Year (%)', fontsize=14)\n",
    "    ax.legend(title='Soil Water Scenario')\n",
    "    ax.yaxis.set_major_formatter(PercentFormatter())\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at the specified path: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc4f88c",
   "metadata": {},
   "source": [
    "### **Analysis of the Final Soybean Vulnerability Curve**\n",
    "\n",
    "This multi-line vulnerability curve is the ultimate output of our soybean analysis. It visualizes the model's most important and sophisticated finding: the powerful interaction between July heat stress and overall water availability.\n",
    "\n",
    "#### **How to Read This Plot**\n",
    "\n",
    "*   The **X-axis** represents July conditions, from cool/cloudy (negative Z-scores) to hot/sunny (positive Z-scores).\n",
    "*   The **Y-axis** shows the predicted percentage change in yield compared to a baseline \"typical year\" (which has both average heat and average water).\n",
    "*   The **three colored lines** represent the vulnerability to July heat under three different seasonal water availability scenarios: Drought, Average, and Wet.\n",
    "\n",
    "#### **Primary Findings**\n",
    "\n",
    "1.  **Water Availability Sets the Yield Potential:**\n",
    "    *   The most striking feature is the clear separation of the curves. The \"Drought\" scenario (orange) is always in the negative, showing that a dry season consistently leads to **below-average yields**, with losses ranging from -10% to over -40%.\n",
    "    *   Conversely, the \"Wet\" scenario (cyan) is the only one that allows for **above-average yields**, with gains of over +10% possible under optimal temperatures.\n",
    "\n",
    "2.  **Heat Stress Determines the Final Outcome:**\n",
    "    *   All three curves show the same **inverted U-shape**, confirming that there is an optimal temperature for soybean in July. Extreme heat (moving to the right) is always damaging.\n",
    "    *   The key interaction is visible in the slopes: the decline in yield due to heat stress is **most severe in a drought year**. For example, moving from the optimal temperature to a \"heatwave\" (Z-score of +2) causes a much larger percentage loss in the \"Drought\" scenario than it does in the \"Wet\" scenario.\n",
    "\n",
    "#### **Overall Conclusion**\n",
    "\n",
    "The model's most powerful finding is that **water availability is the master variable that sets the yield potential for soybean, while July heat stress determines how much of that potential is realized or lost.** A drought year has a low yield ceiling and is highly vulnerable to heatwaves. A wet year not only has a much higher yield potential but also demonstrates greater resilience, suffering a smaller percentage loss when faced with the same level of heat stress. This quantifies the critical, compounding nature of climate risk for soybean production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a66a17",
   "metadata": {},
   "source": [
    "### **Final Soybean Model: Interpretation and Conclusions**\n",
    "\n",
    "This section summarizes the final champion model developed to explain the relationship between monthly climate stressors and soybean yield in Northern Italy. The model is the result of a multi-step workflow designed to be statistically robust, parsimonious, and highly insightful.\n",
    "\n",
    "#### **The Final Champion Model**\n",
    "\n",
    "After a data-driven process of variable selection and extensive iterative refinement, the final, best-performing model was determined to be a Gamma GLM with a complex interactive structure:\n",
    "\n",
    "**Final Model Formula:**\n",
    "```\n",
    "yield_soybean ~ year + bs(lat, df=4) + bs(lon, df=4) + \n",
    "                potential_evaporation_May + solar_rad_Jul_z + \n",
    "                soil_water + precipitation_May + \n",
    "                I(solar_rad_Jul_z**2) + I(precipitation_May**2) + \n",
    "                solar_rad_Jul_z:soil_water + potential_evaporation_May:solar_rad_Jul_z\n",
    "```\n",
    "\n",
    "**Key Performance Metrics:**\n",
    "*   **Akaike Information Criterion (AIC):** `3447.76` (The lowest of all tested models)\n",
    "*   **Pseudo R-squared (CS):** `0.8513` (Explains approx. **85.1%** of the variation in yield)\n",
    "\n",
    "#### **The Modeling Journey: How We Arrived Here**\n",
    "\n",
    "The final model was the product of a systematic, evidence-based process:\n",
    "\n",
    "1.  **Variable Selection:** An **Elastic Net regularization** revealed that soybean yield is influenced by a more complex mix of factors than the previously modeled crops, identifying a broader set of robust climate predictors to carry forward.\n",
    "\n",
    "2.  **Model Refinement (Parsimony):** An initial base model was fitted, and non-significant predictors (`solar_radiation_Aug`, `solar_radiation_Sep`) were removed to create a simpler, more robust model with an improved AIC.\n",
    "\n",
    "3.  **Testing for Non-Linearity:** Guided by EDA and agronomic theory, we tested for non-linear effects one at a time. Adding a quadratic term for `solar_radiation_Jul` (after standardization) and `precipitation_May` both resulted in **massive drops in AIC**, confirming two distinct and critical non-linear relationships.\n",
    "\n",
    "4.  **Testing for Interactions:** We tested a series of plausible, theory-driven interactions. The model was significantly improved by including both the **`solar_rad_Jul_z:soil_water`** (Heat x Water Stress) and the **`potential_evaporation_May:solar_rad_Jul_z`** (Early vs. Mid-season Stress) interactions, each providing a large, statistically significant improvement in model fit.\n",
    "\n",
    "This structured process ensures our final model is not overfit and that its complexity is justified by strong statistical evidence.\n",
    "\n",
    "#### **Detailed Interpretation of the Final Model**\n",
    "\n",
    "*   **Control Variables:**\n",
    "    *   `year`: The positive, significant coefficient confirms a **technological trend**, with yields consistently increasing over time.\n",
    "    *   `bs(lat, df=4)` & `bs(lon, df=4)`: The high significance of the spatial splines confirms that **geography is a dominant driver** of yield.\n",
    "\n",
    "*   **Key Climate Drivers:**\n",
    "    *   **Non-Linear Effects:** The model identified two \"optimum\" conditions. Both `solar_radiation_Jul` and `precipitation_May` have **inverted U-shaped effects**, indicating that yields are maximized at a moderate level of July sun/heat and May rainfall. Too little or too much of either is detrimental.\n",
    "    *   **Interaction 1 (Heat x Water):** The significant `solar_rad_Jul_z:soil_water` interaction confirms that the negative impact of July heat stress is **amplified by drought**. Ample water availability helps the crop tolerate heat.\n",
    "    *   **Interaction 2 (Early x Mid-Season):** The significant `potential_evaporation_May:solar_rad_Jul_z` interaction reveals a compounding effect across the season, where early-season conditions in May modify the crop's response to heat stress in July.\n",
    "\n",
    "#### **Insights from Visualization**\n",
    "\n",
    "*   **The Non-Linear Response Curves:** The yield response plots for `solar_radiation_Jul` and `precipitation_May` visually confirm the **inverted U-shapes**. They allow us to identify the optimal points for these stressors and clearly see how yield declines when conditions deviate from this optimum.\n",
    "\n",
    "*   **The Final Vulnerability Curve (Interaction Plot):** This plot is the ultimate synthesis of the model's findings. By showing the vulnerability to July heat under different water scenarios (Drought, Average, Wet), it tells a powerful, multi-faceted story:\n",
    "    *   **Water Sets the Potential:** The plot clearly shows that achieving an **above-average yield** (+10%) is only possible in a \"Wet\" year. A \"Drought\" year has a much lower yield ceiling and is always predicted to have a below-average yield (from -10% to -40%).\n",
    "    *   **Heat Determines the Outcome:** In all scenarios, extreme heat (moving to the right on the x-axis) causes a sharp decline in yield. However, this decline is **most severe in a drought year**, visually confirming that water-stressed plants are far more vulnerable to heatwaves.\n",
    "\n",
    "#### **Overall Conclusion**\n",
    "\n",
    "The model provides a powerful and nuanced explanation of soybean yield vulnerability. The dominant story is a complex interplay of **heat and water**. The model's core insight is that **water availability is the master variable that sets the yield potential for the season, while July heat stress determines how much of that potential is ultimately realized.** A dry season is a state of chronic stress with a low yield ceiling and extreme vulnerability to heat. Conversely, a wet season not only has a higher yield potential but also provides a crucial buffer, making the crop more resilient to mid-summer heatwaves."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climarisc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
