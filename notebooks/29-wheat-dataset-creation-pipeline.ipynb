{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98574e1b-82a4-47b5-b558-6925ffd7d70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== USER INPUTS (edit) ====\n",
    "\n",
    "# Tag used in output filenames\n",
    "region_tag = \"ITnorth_core41\"      # if balancing drops a cell, feel free to rename to core41 manually\n",
    "\n",
    "# Years (inclusive)\n",
    "start_year = 1982\n",
    "end_year   = 2016\n",
    "years      = list(range(start_year, end_year + 1))\n",
    "\n",
    "# Seasons (list months in SEASON ORDER, start→end)\n",
    "winter_months = [11,12,1,2,3,4,5,6]  # Nov–Jun (wraps over Dec→Jan)\n",
    "spring_months = [3,4,5,6,7]          # Mar–Jul\n",
    "\n",
    "# Paths\n",
    "DERIVED     = r\"..\\italy_core_data\\derived\"\n",
    "MASK_CSV    = r\"..\\italy_core_data\\derived\\mask_core_42_on_gdhy.csv\"\n",
    "\n",
    "# GDHY yield directories (per-year yield_YYYY.nc4 files)\n",
    "GDHY_WINTER_DIR = r\"..\\data\\wheat_winter\"\n",
    "GDHY_SPRING_DIR = r\"..\\data\\wheat_spring\"\n",
    "GDHY_FILE_TMPL  = \"yield_{year}.nc4\"     # change if filenames differ\n",
    "GDHY_VARNAME    = None                   # None → auto-detect (first data_var)\n",
    "\n",
    "# ERA5 monthly averaged GRIBs (one file per year)\n",
    "ERA5_DIR        = r\"..\\data\\climate_monthly_full\"\n",
    "ERA5_FILE_TMPL  = \"era5_land_monthly_{year}.grib\"\n",
    "\n",
    "# Units convenience\n",
    "SSR_TO_MJ = False   # if True, also add solar_radiation_*_MJm2 columns\n",
    "\n",
    "# Month labels\n",
    "month_names = {1:\"Jan\",2:\"Feb\",3:\"Mar\",4:\"Apr\",5:\"May\",6:\"Jun\",7:\"Jul\",8:\"Aug\",9:\"Sep\",10:\"Oct\",11:\"Nov\",12:\"Dec\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98080181-7d29-4fde-af09-c6962577b841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DERIVED = Path(DERIVED); DERIVED.mkdir(exist_ok=True)\n",
    "\n",
    "# --- mask & bbox from your 42-core cells ---\n",
    "m42 = pd.read_csv(MASK_CSV).sort_values([\"lat\",\"lon\"]).reset_index(drop=True)\n",
    "LATC_ALL = m42[\"lat\"].to_numpy()\n",
    "LONC_ALL = m42[\"lon\"].to_numpy()\n",
    "\n",
    "def make_bbox(latc, lonc, pad=0.5):\n",
    "    return dict(\n",
    "        lat_min=float(latc.min() - pad),\n",
    "        lat_max=float(latc.max() + pad),\n",
    "        lon_min=float(lonc.min() - pad),\n",
    "        lon_max=float(lonc.max() + pad),\n",
    "    )\n",
    "\n",
    "# --- file finders ---\n",
    "def yield_path(gdhy_dir: Path, y: int) -> Path:\n",
    "    p = gdhy_dir / GDHY_FILE_TMPL.format(year=y)\n",
    "    if p.exists(): return p\n",
    "    cands = list(gdhy_dir.glob(f\"*{y}*.nc*\"))\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(f\"No GDHY yield for {y} in {gdhy_dir}\")\n",
    "    return cands[0]\n",
    "\n",
    "def era5_path(y: int) -> Path:\n",
    "    p = Path(ERA5_DIR) / ERA5_FILE_TMPL.format(year=y)\n",
    "    if p.exists(): return p\n",
    "    cands = list(Path(ERA5_DIR).glob(f\"*{y}*.grib\"))\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(f\"No ERA5 GRIB for {y} in {ERA5_DIR}\")\n",
    "    return cands[0]\n",
    "\n",
    "# --- ERA5 opener with cropping; returns DataArray (time, lat, lon) ---\n",
    "def open_era5_var_year(y: int, short: str, xr_name: str, bbox: dict) -> xr.DataArray:\n",
    "    f = era5_path(y)\n",
    "    ds = xr.open_dataset(\n",
    "        f, engine=\"cfgrib\",\n",
    "        backend_kwargs=dict(indexpath=\"\", filter_by_keys={\"shortName\": short}),\n",
    "        decode_timedelta=True,\n",
    "    ).rename({\"latitude\":\"lat\",\"longitude\":\"lon\"})\n",
    "    if ds.lat[0] > ds.lat[-1]:\n",
    "        ds = ds.sortby(\"lat\")\n",
    "    if ds.lon.min() < 0:\n",
    "        ds = ds.assign_coords(lon=((ds.lon % 360 + 360) % 360)).sortby(\"lon\")\n",
    "    ds = ds.sel(lat=slice(bbox[\"lat_min\"], bbox[\"lat_max\"]),\n",
    "                lon=slice(bbox[\"lon_min\"], bbox[\"lon_max\"]))\n",
    "    da = ds[xr_name]\n",
    "    if \"expver\" in da.dims:\n",
    "        da = da.isel(expver=-1)\n",
    "    return da\n",
    "\n",
    "# --- 0.1° → 0.5° block-average to GDHY centers (offset 0.25°) ---\n",
    "def bin_to_half_degree(da: xr.DataArray, step=0.5, offset=0.25) -> xr.DataArray:\n",
    "    lat_bins = (offset + step * np.round((da[\"lat\"].values - offset) / step)).astype(np.float64)\n",
    "    lon_bins = (offset + step * np.round((da[\"lon\"].values - offset) / step)).astype(np.float64)\n",
    "    da = da.assign_coords(lat_bin=(\"lat\", lat_bins), lon_bin=(\"lon\", lon_bins))\n",
    "    da_c = da.groupby(\"lat_bin\").mean(\"lat\").groupby(\"lon_bin\").mean(\"lon\")\n",
    "    return da_c.rename({\"lat_bin\":\"lat\",\"lon_bin\":\"lon\"})\n",
    "\n",
    "# --- select a given set of cells by lat/lon value (nearest) ---\n",
    "def select_cells(da: xr.DataArray, latc: np.ndarray, lonc: np.ndarray) -> xr.DataArray:\n",
    "    out = da.sel(lat=xr.DataArray(latc, dims=\"cell\"),\n",
    "                 lon=xr.DataArray(lonc, dims=\"cell\"),\n",
    "                 method=\"nearest\")\n",
    "    return out.assign_coords(cell=(\"cell\", np.arange(len(latc))),\n",
    "                             lat=(\"cell\", latc), lon=(\"cell\", lonc))\n",
    "\n",
    "# --- wrap-around season helpers (Dec→Jan) ---\n",
    "def season_wraps(months: list[int]) -> bool:\n",
    "    \"\"\"True if the season crosses Dec→Jan (e.g., [11,12,1,...]). Assumes months are in season order.\"\"\"\n",
    "    return months != sorted(months)\n",
    "\n",
    "def crop_year_for_series(month: pd.Series, year: pd.Series, pivot_month: int) -> pd.Series:\n",
    "    \"\"\"Year + 1 for months >= pivot_month (e.g., Nov/Dec go to next harvest year).\"\"\"\n",
    "    return year + (month >= pivot_month).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3559b03a-dcc0-47b0-9d7f-2c9e4ab25f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- monthly reducers ----\n",
    "def monthly_means(da_m05: xr.DataArray, months: list[int]) -> xr.DataArray:\n",
    "    return da_m05.where(da_m05[\"time\"].dt.month.isin(months), drop=True)\n",
    "\n",
    "def monthly_totals_from_daily_means(da_m05: xr.DataArray, months: list[int]) -> xr.DataArray:\n",
    "    sel = da_m05.where(da_m05[\"time\"].dt.month.isin(months), drop=True)\n",
    "    days = xr.DataArray(sel[\"time\"].dt.days_in_month, coords={\"time\": sel[\"time\"]}, dims=[\"time\"]).astype(np.float64)\n",
    "    return sel * days\n",
    "\n",
    "# ---- seasonal reducers (crop-year aware) ----\n",
    "def seasonal_reduce(da_m05: xr.DataArray, months: list[int], kind: str) -> xr.DataArray:\n",
    "    \"\"\"kind: 'mean' for state; 'sum' for flux monthly totals.\"\"\"\n",
    "    if kind == \"mean\":\n",
    "        sel = monthly_means(da_m05, months)\n",
    "    elif kind == \"sum\":\n",
    "        sel = monthly_totals_from_daily_means(da_m05, months)\n",
    "    else:\n",
    "        raise ValueError(\"kind must be 'mean' or 'sum'\")\n",
    "    if season_wraps(months):\n",
    "        pivot = months[0]\n",
    "        cy = xr.DataArray(sel[\"time\"].dt.year + (sel[\"time\"].dt.month >= pivot).astype(int),\n",
    "                          coords={\"time\": sel[\"time\"]}, dims=[\"time\"], name=\"year\")\n",
    "        out = sel.groupby(cy).mean(\"time\") if kind == \"mean\" else sel.groupby(cy).sum(\"time\")\n",
    "    else:\n",
    "        out = sel.groupby(\"time.year\").mean(\"time\") if kind == \"mean\" else sel.groupby(\"time.year\").sum(\"time\")\n",
    "        out = out.rename({\"year\":\"year\"})\n",
    "    return out\n",
    "\n",
    "# ---- process one ERA5 variable (returns seasonal_df, monthly_wide_df) ----\n",
    "def process_era5_var_cropyear(short: str, xr_name: str, out_col: str, vtype: str,\n",
    "                              season_months: list[int], latc: np.ndarray, lonc: np.ndarray,\n",
    "                              bbox: dict, years: list[int], month_names: dict, ssr_to_mj: bool=False):\n",
    "    \"\"\"\n",
    "    Crop-year–aware processor (safe for wrapping seasons like Nov→Jun).\n",
    "    Returns: (seasonal_df, monthly_wide_df) with harvest-year 'year'.\n",
    "    vtype: 'state' (mean) or 'flux' (sum of monthly totals).\n",
    "    \"\"\"\n",
    "\n",
    "    wraps = season_wraps(season_months)\n",
    "    pivot = season_months[0] if wraps else None\n",
    "\n",
    "    # Calendar years to open:\n",
    "    # - non-wrap: exactly the requested years\n",
    "    # - wrap: include the *year before* start so Nov–Dec for the first harvest year exist\n",
    "    y0 = years[0] - 1 if wraps else years[0]\n",
    "    y1 = years[-1]\n",
    "    cal_years = list(range(y0, y1 + 1))\n",
    "\n",
    "    monthly_rows = []\n",
    "\n",
    "    for y in cal_years:\n",
    "        da = open_era5_var_year(y, short, xr_name, bbox)\n",
    "\n",
    "        # unit conversions on monthly fields\n",
    "        if out_col == \"temperature\":\n",
    "            da = da - 273.15\n",
    "        if out_col == \"precipitation\":\n",
    "            da = da * 1000.0          # m -> mm (daily mean)\n",
    "        if out_col == \"potential_evaporation\":\n",
    "            da = -da * 1000.0         # flip sign, m -> mm (daily mean)\n",
    "\n",
    "        da05 = bin_to_half_degree(da)\n",
    "\n",
    "        # Build monthly values for requested months (state vs flux)\n",
    "        if vtype == \"state\":\n",
    "            dam = monthly_means(da05, season_months)                        # monthly means\n",
    "        elif vtype == \"flux\":\n",
    "            dam = monthly_totals_from_daily_means(da05, season_months)      # monthly totals\n",
    "        else:\n",
    "            raise ValueError(\"vtype must be 'state' or 'flux'\")\n",
    "\n",
    "        # Select analysis cells and go to a long table\n",
    "        sub = select_cells(dam, latc, lonc)\n",
    "        df = sub.to_dataframe(name=out_col).reset_index()\n",
    "\n",
    "        # Calendar month/year and days_in_month\n",
    "        t = pd.to_datetime(df[\"time\"])\n",
    "        df[\"month\"] = t.dt.month\n",
    "        df[\"month_name\"] = df[\"month\"].map(month_names)\n",
    "        df[\"cal_year\"] = t.dt.year\n",
    "        df[\"days\"] = t.dt.days_in_month.astype(float)\n",
    "\n",
    "        # Assign harvest year (crop-year)\n",
    "        if wraps:\n",
    "            df[\"year\"] = df[\"cal_year\"] + (df[\"month\"] >= pivot).astype(int)\n",
    "        else:\n",
    "            df[\"year\"] = df[\"cal_year\"]\n",
    "\n",
    "        # Keep only season months\n",
    "        df = df[df[\"month\"].isin(season_months)].copy()\n",
    "\n",
    "        monthly_rows.append(df[[\"lat\",\"lon\",\"year\",\"month\",\"month_name\",\"days\",out_col]])\n",
    "\n",
    "        if (y - cal_years[0]) % 5 == 0:\n",
    "            print(f\"{out_col}: processed {y}\", flush=True)\n",
    "\n",
    "    # All monthly rows across needed calendar years\n",
    "    m = pd.concat(monthly_rows, ignore_index=True)\n",
    "\n",
    "    # Keep only harvest years in the requested range\n",
    "    m = m[(m[\"year\"] >= years[0]) & (m[\"year\"] <= years[-1])].copy()\n",
    "\n",
    "    # ----- Seasonal from monthly (robust across wrap) -----\n",
    "    keys = [\"lat\",\"lon\",\"year\"]\n",
    "\n",
    "    if vtype == \"flux\":\n",
    "        # Already monthly totals → seasonal total = sum\n",
    "        seas = (m.groupby(keys, as_index=False)[out_col].sum())\n",
    "    else:\n",
    "        # State monthly means → seasonal days-weighted mean\n",
    "        num = (m.assign(wx=m[out_col]*m[\"days\"])\n",
    "                 .groupby(keys, as_index=False)[[\"wx\"]].sum()\n",
    "                 .rename(columns={\"wx\": \"num\"}))\n",
    "        den = (m.groupby(keys, as_index=False)[[\"days\"]].sum()\n",
    "                 .rename(columns={\"days\": \"den\"}))\n",
    "        seas = num.merge(den, on=keys, how=\"inner\")\n",
    "        seas[out_col] = seas[\"num\"] / seas[\"den\"]\n",
    "        seas = seas[keys + [out_col]]\n",
    "\n",
    "    # Consistent sort\n",
    "    seasonal_df = seas.sort_values(keys).reset_index(drop=True)\n",
    "\n",
    "    # ----- Monthly wide for just this season -----\n",
    "    mon_order = [month_names[mn] for mn in season_months]\n",
    "    wide = (m.pivot_table(index=keys, columns=\"month_name\", values=out_col, aggfunc=\"first\")\n",
    "              .reset_index())\n",
    "    for mn in mon_order:\n",
    "        if mn not in wide.columns:\n",
    "            wide[mn] = np.nan\n",
    "    wide = wide[keys + mon_order]\n",
    "    wide = wide.rename(columns={mn: f\"{out_col}_{mn}\" for mn in mon_order})\n",
    "\n",
    "    # Optional SSR copies in MJ/m²\n",
    "    if out_col == \"solar_radiation\" and ssr_to_mj:\n",
    "        for mn in mon_order:\n",
    "            col = f\"solar_radiation_{mn}\"\n",
    "            if col in wide.columns:\n",
    "                wide[f\"{col}_MJm2\"] = wide[col] / 1e6\n",
    "\n",
    "    return seasonal_df, wide\n",
    "\n",
    "# ---- build yield panel for a given crop dir and cell list ----\n",
    "def build_yield_panel(gdhy_dir: str, crop_name: str, latc: np.ndarray, lonc: np.ndarray) -> pd.DataFrame:\n",
    "    gdhy_dir = Path(gdhy_dir)\n",
    "    rows = []\n",
    "    for y in years:\n",
    "        f = yield_path(gdhy_dir, y)\n",
    "        ds = xr.open_dataset(f)\n",
    "        varname = GDHY_VARNAME or [v for v in ds.data_vars][0]\n",
    "        da = ds[varname].squeeze()\n",
    "        if set((\"lat\",\"lon\")).issubset(da.dims):\n",
    "            da = da.transpose(\"lat\",\"lon\")\n",
    "        else:\n",
    "            raise ValueError(f\"{f} missing lat/lon dims; got {da.dims}\")\n",
    "        # map the requested lat/lon centers to indices\n",
    "        lat_vals = da[\"lat\"].values; lon_vals = da[\"lon\"].values\n",
    "        def idx(val, axis_vals):\n",
    "            i = int(np.argmin(np.abs(axis_vals - val)))\n",
    "            if not np.isclose(axis_vals[i], val, atol=5e-4):\n",
    "                raise ValueError(\"Grid mismatch locating indices.\")\n",
    "            return i\n",
    "        ilat = np.array([idx(v, lat_vals) for v in latc])\n",
    "        ilon = np.array([idx(v, lon_vals) for v in lonc])\n",
    "        vals = da.values[ilat, ilon].astype(\"float32\")\n",
    "        rows.append(pd.DataFrame({\"year\": y, \"lat\": latc, \"lon\": lonc, f\"yield_{crop_name}\": vals}))\n",
    "    return pd.concat(rows, ignore_index=True).sort_values([\"lat\",\"lon\",\"year\"]).reset_index(drop=True)\n",
    "\n",
    "# ---- enforce balanced panel by yield (keeps only cells with all years present) ----\n",
    "def balance_by_yield(yield_df: pd.DataFrame, yield_col: str) -> tuple[pd.DataFrame, np.ndarray, np.ndarray]:\n",
    "    yrs_needed = len(years)\n",
    "    cov = (yield_df.assign(ok=~yield_df[yield_col].isna())\n",
    "                   .groupby([\"lat\",\"lon\"])[\"ok\"].sum())\n",
    "    keep_pairs = cov[cov == yrs_needed].index.to_list()\n",
    "    keep = pd.DataFrame(keep_pairs, columns=[\"lat\",\"lon\"])\n",
    "    out = (yield_df.merge(keep, on=[\"lat\",\"lon\"], how=\"inner\")\n",
    "                  .sort_values([\"lat\",\"lon\",\"year\"]).reset_index(drop=True))\n",
    "    latc = keep[\"lat\"].to_numpy()\n",
    "    lonc = keep[\"lon\"].to_numpy()\n",
    "    return out, latc, lonc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9878db6b-cb81-4270-94c6-1d98930892d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winter wheat: kept 41 cells after balancing.\n",
      "temperature: processed 1981\n",
      "temperature: processed 1986\n",
      "temperature: processed 1991\n",
      "temperature: processed 1996\n",
      "temperature: processed 2001\n",
      "temperature: processed 2006\n",
      "temperature: processed 2011\n",
      "temperature: processed 2016\n",
      "precipitation: processed 1981\n",
      "precipitation: processed 1986\n",
      "precipitation: processed 1991\n",
      "precipitation: processed 1996\n",
      "precipitation: processed 2001\n",
      "precipitation: processed 2006\n",
      "precipitation: processed 2011\n",
      "precipitation: processed 2016\n",
      "soil_water: processed 1981\n",
      "soil_water: processed 1986\n",
      "soil_water: processed 1991\n",
      "soil_water: processed 1996\n",
      "soil_water: processed 2001\n",
      "soil_water: processed 2006\n",
      "soil_water: processed 2011\n",
      "soil_water: processed 2016\n",
      "solar_radiation: processed 1981\n",
      "solar_radiation: processed 1986\n",
      "solar_radiation: processed 1991\n",
      "solar_radiation: processed 1996\n",
      "solar_radiation: processed 2001\n",
      "solar_radiation: processed 2006\n",
      "solar_radiation: processed 2011\n",
      "solar_radiation: processed 2016\n",
      "potential_evaporation: processed 1981\n",
      "potential_evaporation: processed 1986\n",
      "potential_evaporation: processed 1991\n",
      "potential_evaporation: processed 1996\n",
      "potential_evaporation: processed 2001\n",
      "potential_evaporation: processed 2006\n",
      "potential_evaporation: processed 2011\n",
      "potential_evaporation: processed 2016\n",
      "Saved → ..\\italy_core_data\\derived\\wheat_winter_ITnorth_core41_1982_2016_allstressors.csv\n",
      "Saved → ..\\italy_core_data\\derived\\wheat_winter_ITnorth_core41_1982_2016_allstressors_with_monthly.csv\n"
     ]
    }
   ],
   "source": [
    "# ===== WINTER WHEAT =====\n",
    "crop_name = \"wheat_winter\"\n",
    "latc = LATC_ALL.copy(); lonc = LONC_ALL.copy()\n",
    "bbox = make_bbox(latc, lonc)\n",
    "\n",
    "# 1) Yield panel\n",
    "yield_df = build_yield_panel(GDHY_WINTER_DIR, crop_name, latc, lonc)\n",
    "YIELD_COL = f\"yield_{crop_name}\"\n",
    "yield_df, latc, lonc = balance_by_yield(yield_df, YIELD_COL)\n",
    "bbox = make_bbox(latc, lonc)\n",
    "print(f\"Winter wheat: kept {len(np.unique(list(zip(latc,lonc)), axis=0))} cells after balancing.\")\n",
    "\n",
    "# 2) ERA5 variables\n",
    "vars_cfg = [\n",
    "    (\"2t\",\"t2m\",\"temperature\",\"state\"),\n",
    "    (\"tp\",\"tp\",\"precipitation\",\"flux\"),\n",
    "    (\"swvl1\",\"swvl1\",\"soil_water\",\"state\"),\n",
    "    (\"ssr\",\"ssr\",\"solar_radiation\",\"flux\"),\n",
    "    (\"pev\",\"pev\",\"potential_evaporation\",\"flux\"),\n",
    "]\n",
    "seasonal_tables = []; monthly_tables = []\n",
    "for short, xr_name, out_col, vtype in vars_cfg:\n",
    "    seas, mon = process_era5_var_cropyear(short, xr_name, out_col, vtype,\n",
    "                                          winter_months, latc, lonc, bbox, years, month_names, SSR_TO_MJ)\n",
    "    seasonal_tables.append(seas); monthly_tables.append(mon)\n",
    "\n",
    "# 3) Merge seasonal into base & save\n",
    "base = yield_df.copy()\n",
    "for tbl in seasonal_tables:\n",
    "    base = base.merge(tbl, on=[\"lat\",\"lon\",\"year\"], how=\"inner\")\n",
    "assert len(base) == len(yield_df) and base.isna().sum().sum()==0\n",
    "\n",
    "out_seasonal = DERIVED / f\"{crop_name}_{region_tag}_{start_year}_{end_year}_allstressors.csv\"\n",
    "base.to_csv(out_seasonal, index=False)\n",
    "print(\"Saved →\", out_seasonal)\n",
    "\n",
    "# 4) Add monthly & save\n",
    "enriched = base.copy()\n",
    "for mon in monthly_tables:\n",
    "    enriched = enriched.merge(mon, on=[\"lat\",\"lon\",\"year\"], how=\"inner\")\n",
    "assert len(enriched) == len(base) and enriched.isna().sum().sum()==0\n",
    "\n",
    "out_monthly = DERIVED / f\"{crop_name}_{region_tag}_{start_year}_{end_year}_allstressors_with_monthly.csv\"\n",
    "enriched.to_csv(out_monthly, index=False)\n",
    "print(\"Saved →\", out_monthly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ccaff46-ca6e-4332-9cfd-c8c9c07d675d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spring wheat: kept 41 cells after balancing.\n",
      "temperature: processed 1982\n",
      "temperature: processed 1987\n",
      "temperature: processed 1992\n",
      "temperature: processed 1997\n",
      "temperature: processed 2002\n",
      "temperature: processed 2007\n",
      "temperature: processed 2012\n",
      "precipitation: processed 1982\n",
      "precipitation: processed 1987\n",
      "precipitation: processed 1992\n",
      "precipitation: processed 1997\n",
      "precipitation: processed 2002\n",
      "precipitation: processed 2007\n",
      "precipitation: processed 2012\n",
      "soil_water: processed 1982\n",
      "soil_water: processed 1987\n",
      "soil_water: processed 1992\n",
      "soil_water: processed 1997\n",
      "soil_water: processed 2002\n",
      "soil_water: processed 2007\n",
      "soil_water: processed 2012\n",
      "solar_radiation: processed 1982\n",
      "solar_radiation: processed 1987\n",
      "solar_radiation: processed 1992\n",
      "solar_radiation: processed 1997\n",
      "solar_radiation: processed 2002\n",
      "solar_radiation: processed 2007\n",
      "solar_radiation: processed 2012\n",
      "potential_evaporation: processed 1982\n",
      "potential_evaporation: processed 1987\n",
      "potential_evaporation: processed 1992\n",
      "potential_evaporation: processed 1997\n",
      "potential_evaporation: processed 2002\n",
      "potential_evaporation: processed 2007\n",
      "potential_evaporation: processed 2012\n",
      "Saved → ..\\italy_core_data\\derived\\wheat_spring_ITnorth_core41_1982_2016_allstressors.csv\n",
      "Saved → ..\\italy_core_data\\derived\\wheat_spring_ITnorth_core41_1982_2016_allstressors_with_monthly.csv\n"
     ]
    }
   ],
   "source": [
    "# ===== SPRING WHEAT =====\n",
    "crop_name = \"wheat_spring\"\n",
    "latc = LATC_ALL.copy(); lonc = LONC_ALL.copy()\n",
    "bbox = make_bbox(latc, lonc)\n",
    "\n",
    "# 1) Yield panel\n",
    "yield_df = build_yield_panel(GDHY_SPRING_DIR, crop_name, latc, lonc)\n",
    "YIELD_COL = f\"yield_{crop_name}\"\n",
    "yield_df, latc, lonc = balance_by_yield(yield_df, YIELD_COL)\n",
    "bbox = make_bbox(latc, lonc)\n",
    "print(f\"Spring wheat: kept {len(np.unique(list(zip(latc,lonc)), axis=0))} cells after balancing.\")\n",
    "\n",
    "# 2) ERA5 variables\n",
    "vars_cfg = [\n",
    "    (\"2t\",\"t2m\",\"temperature\",\"state\"),\n",
    "    (\"tp\",\"tp\",\"precipitation\",\"flux\"),\n",
    "    (\"swvl1\",\"swvl1\",\"soil_water\",\"state\"),\n",
    "    (\"ssr\",\"ssr\",\"solar_radiation\",\"flux\"),\n",
    "    (\"pev\",\"pev\",\"potential_evaporation\",\"flux\"),\n",
    "]\n",
    "seasonal_tables = []; monthly_tables = []\n",
    "for short, xr_name, out_col, vtype in vars_cfg:\n",
    "    seas, mon = process_era5_var_cropyear(short, xr_name, out_col, vtype,\n",
    "                                          spring_months, latc, lonc, bbox, years, month_names, SSR_TO_MJ)\n",
    "    seasonal_tables.append(seas); monthly_tables.append(mon)\n",
    "\n",
    "# 3) Merge seasonal into base & save\n",
    "base = yield_df.copy()\n",
    "for tbl in seasonal_tables:\n",
    "    base = base.merge(tbl, on=[\"lat\",\"lon\",\"year\"], how=\"inner\")\n",
    "assert len(base) == len(yield_df) and base.isna().sum().sum()==0\n",
    "\n",
    "out_seasonal = DERIVED / f\"{crop_name}_{region_tag}_{start_year}_{end_year}_allstressors.csv\"\n",
    "base.to_csv(out_seasonal, index=False)\n",
    "print(\"Saved →\", out_seasonal)\n",
    "\n",
    "# 4) Add monthly & save\n",
    "enriched = base.copy()\n",
    "for mon in monthly_tables:\n",
    "    enriched = enriched.merge(mon, on=[\"lat\",\"lon\",\"year\"], how=\"inner\")\n",
    "assert len(enriched) == len(base) and enriched.isna().sum().sum()==0\n",
    "\n",
    "out_monthly = DERIVED / f\"{crop_name}_{region_tag}_{start_year}_{end_year}_allstressors_with_monthly.csv\"\n",
    "enriched.to_csv(out_monthly, index=False)\n",
    "print(\"Saved →\", out_monthly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc627ece-3712-41be-961a-24206d801de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved stacked long wheat dataset → ..\\italy_core_data\\derived\\wheat_both_ITnorth_core41_1982_2016_allstressors_with_monthly_long.csv\n",
      "Shape: (2870, 55)\n",
      "Columns (first 20): ['lat', 'lon', 'year', 'wheat_type', 'yield_wheat', 'temperature', 'precipitation', 'soil_water', 'solar_radiation', 'potential_evaporation', 'temperature_Jan', 'temperature_Feb', 'temperature_Mar', 'temperature_Apr', 'temperature_May', 'temperature_Jun', 'temperature_Jul', 'temperature_Nov', 'temperature_Dec', 'precipitation_Jan']\n"
     ]
    }
   ],
   "source": [
    "# === STACK WINTER + SPRING WHEAT INTO ONE LONG FILE (TYPE-LABELED) ===\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---- EDIT THESE 3 LINES ----\n",
    "DERIVED    = Path(r\"..\\italy_core_data\\derived\")\n",
    "region_tag = \"ITnorth_core41\"   # use the same tag you used for the per-type exports\n",
    "start_year, end_year = 1982, 2016\n",
    "# ----------------------------\n",
    "\n",
    "winter_csv = DERIVED / f\"wheat_winter_{region_tag}_{start_year}_{end_year}_allstressors_with_monthly.csv\"\n",
    "spring_csv = DERIVED / f\"wheat_spring_{region_tag}_{start_year}_{end_year}_allstressors_with_monthly.csv\"\n",
    "out_csv    = DERIVED / f\"wheat_both_{region_tag}_{start_year}_{end_year}_allstressors_with_monthly_long.csv\"\n",
    "\n",
    "# ---- helpers ----\n",
    "def load_and_tag(p: Path, wheat_type: str) -> pd.DataFrame:\n",
    "    \"\"\"Load CSV, tag wheat_type, normalize yield_* -> yield_wheat.\"\"\"\n",
    "    df = pd.read_csv(p)\n",
    "    df[\"wheat_type\"] = wheat_type\n",
    "    ycols = [c for c in df.columns if c.startswith(\"yield_\")]\n",
    "    if not ycols:\n",
    "        raise ValueError(f\"No yield_* column found in {p.name}\")\n",
    "    if \"yield_wheat\" not in df.columns:\n",
    "        df[\"yield_wheat\"] = df[ycols[0]]\n",
    "        for c in ycols:\n",
    "            if c != \"yield_wheat\":\n",
    "                df.drop(columns=c, inplace=True)\n",
    "    return df\n",
    "\n",
    "dw = load_and_tag(winter_csv, \"winter\")\n",
    "ds = load_and_tag(spring_csv, \"spring\")\n",
    "\n",
    "# required keys & seasonals in each input\n",
    "key_cols = [\"lat\",\"lon\",\"year\",\"wheat_type\"]\n",
    "seasonal_cols = [\"yield_wheat\",\"temperature\",\"precipitation\",\"soil_water\",\"solar_radiation\",\"potential_evaporation\"]\n",
    "for req in seasonal_cols:\n",
    "    for d, name in [(dw, winter_csv.name), (ds, spring_csv.name)]:\n",
    "        if req not in d.columns:\n",
    "            raise ValueError(f\"Missing seasonal column '{req}' in {name}\")\n",
    "\n",
    "# ---- robust monthly union (no string parsing) ----\n",
    "mon_names = [\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]\n",
    "base_vars = [\"temperature\",\"precipitation\",\"soil_water\",\"solar_radiation\",\"potential_evaporation\"]\n",
    "\n",
    "def find_monthly_cols(df: pd.DataFrame):\n",
    "    cols = []\n",
    "    for b in base_vars:\n",
    "        for m in mon_names:\n",
    "            c = f\"{b}_{m}\"\n",
    "            if c in df.columns:\n",
    "                cols.append(c)\n",
    "    return cols\n",
    "\n",
    "cols_all = set(find_monthly_cols(dw)) | set(find_monthly_cols(ds))\n",
    "monthly_union = [f\"{b}_{m}\" for b in base_vars for m in mon_names if f\"{b}_{m}\" in cols_all]\n",
    "\n",
    "# ensure both frames have the full monthly schema (add NaNs where missing)\n",
    "for c in monthly_union:\n",
    "    if c not in dw.columns: dw[c] = np.nan\n",
    "    if c not in ds.columns: ds[c] = np.nan\n",
    "\n",
    "# order columns consistently\n",
    "ordered_cols = key_cols + seasonal_cols + monthly_union\n",
    "dw = dw[ordered_cols].sort_values([\"lat\",\"lon\",\"year\"]).reset_index(drop=True)\n",
    "ds = ds[ordered_cols].sort_values([\"lat\",\"lon\",\"year\"]).reset_index(drop=True)\n",
    "\n",
    "# stack long\n",
    "combined = pd.concat([dw, ds], ignore_index=True).sort_values([\"lat\",\"lon\",\"year\",\"wheat_type\"]).reset_index(drop=True)\n",
    "\n",
    "# sanity checks\n",
    "dups = combined.duplicated([\"lat\",\"lon\",\"year\",\"wheat_type\"]).sum()\n",
    "assert dups == 0, f\"Found duplicated keys: {dups}\"\n",
    "assert \"yield_wheat\" in combined.columns\n",
    "\n",
    "# save\n",
    "combined.to_csv(out_csv, index=False)\n",
    "print(\"Saved stacked long wheat dataset →\", out_csv)\n",
    "print(\"Shape:\", combined.shape)\n",
    "print(\"Columns (first 20):\", combined.columns[:20].tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
